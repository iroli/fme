Для квадратного корня метода, к-рый применяется обычно в случае положительно определенной матрицы $A$, получена наиболее сильная оценка

\[
\left\|F_{M}\right\|_{E} \leqslant C\|A\|_{E} \cdot \varepsilon .
\]

Существуют прямые методы (Жордана, окаймления, сопряженных градиентов), для к-рых непосредственное применение схемы обратного анализа не приводит к әффективным оценкам. В этих случаях при исследовании Н. п. применяются и иные соображения (см. [6][9]).

Tum.: [1] G ive n s W., "U. S. Atomic Energy Commiss. Repts. Ser. OR NL», 1954, № 1574; [2] W i I k i n s o n J. H., Rounding errors in algebra ic processes, L., 1963; [3] у и л к и нс о н Д ж.-Х., Алгебраическая проблема собственных значений, пер. с англ., М., 1970; [4] В о е в о д и н В. В., Ошибки округления и устойчивость в прямых методах линейной алгеб-

![](https://cdn.mathpix.com/cropped/2023_07_08_1f79fef75714830312b7g-1.jpg?height=44&width=831&top_left_y=643&top_left_x=119)
s o n J. H., "Communs Assoc. Comput. Math.», 1975, v. 18, ㅇ․ 1, p. 20-24; [7] B r o y d e n C. G., «J. Inst. Math. and Appl.», 1974, v. 14, No 2, p. 131 - 40; [8] R e i d J. K., в $\mathrm{kH}$.: Iarge, Sparse'sets of Linear Equations, L. - N. Y., 1971 , p. 231-

![](https://cdn.mathpix.com/cropped/2023_07_08_1f79fef75714830312b7g-1.jpg?height=50&width=831&top_left_y=779&top_left_x=120)
Н. п. округления или погре шности м е т о д а возникает при решении задач, где решение является результатом большого числа последовательно выполняемых арифметич. операций.

Значительная часть таких задач связана с решением алгебраич. задач, линейных или нелинейных (см. выше). В свою очередь среди алгебраич. задач наиболее распространены задачи, возникающие при аппроксимации дифференциальных уравнений. Этим задачам свойственны нек-рые специфич. особенности.

Н. п. метода решенія задачи происходит по тем же или по более простым законам, что и Н. п. вычислительной погрешности; Н. п. метода исследуется при оценке метода решения задачи.

При исследовании накопления вычислительной погрешности различалот два подхода. В первом случае считают, что вычис лительные погрешности на каждом шаге вносятся самым неблагоприятным образом и получают ма ор антную оценку погрешности. Во втором случае считают, что эти погрешности случайны с определенным законом распределения.

Характер Н. п. зависит от решаемой задачи, метода решения и ряда других факторов, на первый взгляд могущих показаться несущественными; сюда относятся форма записи чисел в ЭВМ (с фиксированной запятой или с плавающей запятой), порядок выполнения арифметич. операций и т. д. Напр., в задаче вычисления суммы $N$ чисел

\[
A_{N}=a_{1}+\ldots+a_{N}
\]

существенен порядок выполнения операций. Пусть вычисления производятся ніа машине с плаваюшей запятой с $t$ двоичными разрядами и все числа лежат в пределах $1 / 2<\left|a_{n}\right| \leqslant 1$. При непосредственном вычислении $A_{N}$ с помощью рекуррентной формулы

\[
A_{n+1}=A_{n}+a_{n}, n=1, \ldots, N-1 \text {, }
\]

мажорантная оценка погрешности имеет порядок $2^{-t} N$. Можно поступить иначе (см. [1]). При вычислении попарных сумм $A_{k}^{1}=a_{2 k-1}+a_{2 k}$ (если $N=2 l+1$ нечетно) полагают $A_{l+1}^{\mathbf{1}}=a_{2 l+1}$. Далее вычисляются их попарные суммы $A_{k}^{2}=A_{2 k-1}^{1}+A_{2 k}^{1}$ и т. д. При $2^{m-1}<N \leqslant 2^{m}$ после $m$ шагов образования попарных сумм по формулам

\[
A_{k}^{q}=A_{2 k-1}^{q-1}+A_{2 k}^{q-1}, A_{k}^{0} \equiv a_{k},
\]

получают $A_{1}^{m}=A_{N}$; мажорантная оценка погрешности порядка $2^{-1} \log _{2} N$.

В типичных задачах величины $a_{m}$ вычисляются по формулам, в частности рекуррентным, или поступают последовательно в оперативную память ЭВМ; в этих случаях применение описанного приема приводит к увеличению загрузки памяти ЭВМ. Однако можно организовать последовательность вычислений так, что загрузка оперативной памяти не будет превосходить $\sim \log _{2} N$ ячеек.

При численном решении дифференциальных уравнений возможны следующие случаи. При стремлении шага сетки $h$ к нулю погрешность растет как $(a(h))^{h^{-q}}$, где $q>0$, a $\varlimsup_{h \rightarrow 0}|a(h)|>1$. Такие методы решения задач относят к классу н е у с т о й ч и в ы х. Их применение носит әпизодич. характер.

Для у с т о й ч и в ы х методов характерен рост погрештости как $\boldsymbol{A}(h) h-q$, где $\varlimsup_{h \rightarrow 0}|\boldsymbol{A}(h)|<\infty$. Оценка погрешности таких методов обычно производится следующим образом. Строится уравнение относительно возмущения, вносимого или округлением, или погрешностями метода и затем исследуется решение әтого уравнения (см. [2], [3]).

В более сложных случаях применяется м е т о д Эк в. и а ле н т ны х в о м у щ е н й й (см. [1], [4]), развитый в отношении задачи исследования накопления вычислительной погрешности при решении дифференциальных уравнений (см. [3], [5], [6]). Вычисления по нек-рой расчетной схеме с округлениями рассматриваются как вычисления без округлений, но для уравнения с возмущенными коәффициентами. Сравнивая решение исходного сеточного уравнения с решением уравнения с возмущенными коәфффицентами получают оценку погрешности.

Уделяется существенное внимание выбору метода по возможности с меньшими значениями $q$ и $\boldsymbol{A}(h)$. При фиксированном методе решения задачи расчетные формулы обычно удается преобразовать к виду, где $q \leqslant 1$ (см. [3], [5]). Это особенно существенно в случае обыкновенных дифференциальных уравнений, где число шагов в отдельных случаях оказывается очень большим.

Величина $A(h)$ может сильно расти с ростом промежутка интегрирования. Поэтому стараются применять методы по возможности с меньшим значением $\boldsymbol{A}(h)$. В случае задачи Коши ошибка округления на каждом конкретном шаге по отношению к последующим шагам может рассматриваться как ошибка в начальном условии. Поэтому нижняя грань $A(h)$ зависит от характеристики расхождения близких решений дифференциального уравнения, определяемого уравнением в вариациях.

В случае численного решения обыкновенного дифференциального уравнения $y^{\prime}=f(x, y)$ уравнение в вариациях имеет вид

\[
\eta^{\prime}=f_{y}(x, y) \eta+S
\]

и потому при решении задачи на отрезке $\left(x_{0}, X\right)$ нельзя рассчитывать на константу $\boldsymbol{A}(h)$ в мажорантной оценке вычислительной погрешности существенно лучшую, чем

\[
\int_{x_{0}}^{X} e^{\int_{x}^{X} f_{y}(t, y(t)) d t} d x .
\]

Поэтому при решении этой задачи наиболее употребительны одношаговые методы типа Рунге - Кутта или методы типа Адамса (см. [3], [7]), где Н. п. в основном определяется решением уравнения в вариациях.

Для ряда методов главный член погрешности метода накапливается по подобному закону, в то время как вычислительная погрешность накапливается существенно быстрее (см. [3]). Область практич. применимости таких методов оказывается существенно уже.

Накопление вычислительной погрешности существенно зависит от метода, применяемого для решения сеточной задачи. Напр., при решении сеточных краевых за-
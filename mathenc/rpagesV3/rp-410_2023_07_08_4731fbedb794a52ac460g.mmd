личин. Разработано много способов повышения эффективности моделирования.

А лгоритмы М.-К. м. для оце нки мног ок р а т ны и н т е г р а л о в. Пусть необходимо оценить интеграл $J=\int h(x) d x$ по мере Лебега в евклидовом $s$-мерном пространстве $X$ и $f_{\xi}(x)$ - плотность вероятности такая, что $J$ можно записать в виде математич. ожидания следующим образом:

\[
J=\int_{X} f_{\xi}(x) \frac{h(x)}{f_{\xi}(x)} d x=\mathrm{E}_{\zeta}
\]

где $\zeta=h(\xi) / f_{\xi}(\xi)$. Моделируя $\xi$ на ЭВМ, можно получить $N$ выборочных значений $x_{1}, \ldots, x_{N}$ В закона больших чисел

\[
J \approx J_{N}=\frac{\sum_{k=1}^{N} h\left(x_{k}\right) / f\left(x_{k}\right)}{N} .
\]

Одновременно можно оценить среднеквадратичную погрешность $J_{N}$, т. е. величину $\sigma_{N}=(\mathrm{D} \zeta / N)^{1 / 2}$, и приближенно построить подходящий доверительный интервал для $J$. Выбором плотности $f$ можно распорядиться для получения оценки с возможно меньшей дисперсией. Напр., если $0<m_{1} \leqslant h / f \leqslant m_{2}<+\infty$, то $\mathrm{D} \zeta \leqslant\left(m_{2}-m_{1}\right)^{2} / 4$, и если $f=h / J$, то $\mathrm{D} \zeta=0$. Соответствующие алгоритмы наз. с у щ е с т в е н но й в ыбор ко й (вы бор ко й по в а жа ости). Другая общая модификация - м е т о д в д е ле ни я г л а в н о й ч а с т и - строится в тех случаях, когда определена функция $h_{0} \approx h$ с известным значением интеграла. Иногда полезны сочетания М.-К. М. с классич. квадратурами - т. н. с л уч а й ны е к в а д р ат у р ны е ф о р м у лы, основная идея к-рых состоит в том, что узлы и коәфффициенты какой-либо квадратурной суммы (напр., интерполяционной) выбираются случайно из распределения, обеспечивающего несмещенность получаемой оценки интеграла [3]. Частными случаями этих формул являются: т. н. м ет о д с ло и с т о й в ы б о р к и, в к-ром узлы выбираются по одному в каждой части фиксированного разбиения области интегрирования, а коәффициенты пропорциональны соответствующим объемам; так наз. ме т о с имме т р ич н о й вы бор к и, к-рый в случае интегрирования по интервалу $(0,1)$ определяется выражением (см. [10])

\[
2 J=\mathrm{E}\left[(h(\xi)+h(1-\xi)) / f_{\xi}(\xi)\right] .
\]

При әтом порядок скорости сходимости М.-К. м. повышается и в нек-рых случаях становится максимально возможным на рассматриваемом классе задач.

В общем случае область интегрирования разбивается на параллелепипеды. В каждом параллелепипеде значение интеграла вычисляется через среднее значение в случайной точке и точке, симметричной ей относительно центра параллелепипеда.

Ряд модификаций М.-К. м. основан на (может быть, формальном) представлении искомой величины в виде двукратного интеграла:

\[
J=\int_{X} \int_{Y} f(x, y) h(x, y) d x d y=\mathrm{E} \zeta,
\]

где $\zeta=h(\xi, \eta)$, а вектор $(\xi, \eta)$ распределен с плотностью $f(x, y)$. Известно, что $\mathrm{E} \zeta=\mathrm{EE}(\zeta \mid \xi)$ и

\[
\mathrm{D} \zeta=\mathrm{DE}(\zeta \mid \xi)+\mathrm{ED}(\zeta \mid \xi)=A_{1}+A_{2},
\]

где $E(\zeta \mid \xi)$ - условное математич. ожидание, а $D(\xi \mid \xi)-$ условная дисперсия $\zeta$ для фиксированного значения $\xi$. Формула (1) широко используется в М.-К. м. В частности, она показывает, что $D E(\zeta \mid \xi)<D \zeta$, т. е. аналитич. осреднение по какой-либо переменной увели- чивает точность М.-К. м. Однако при этом может значительно возрасти объем вычислений. Для ЭВМ время, необходимое для достижения заданной погрешности, пропорционально величине $t \mathrm{D} \zeta$, где $t-$ среднее время получения одного значения そ. По этому критерию оптимизируется ме т о д р а с е пл ен и я, простейший вариант к-рого состоит в использовании несмещенной оценки:

\[
\zeta_{n}=\left[\sum_{k=1}^{n} h\left(\xi, \eta_{k}\right)\right] / n
\]

где $\eta_{1}, . ., \eta_{n}$ - условно независимы и распределены

![](https://cdn.mathpix.com/cropped/2023_07_08_4731fbedb794a52ac460g-1.jpg?height=42&width=831&top_left_y=535&top_left_x=994)
можно получить оптимальное значение

\[
n=\left[\left(A_{2} / A_{1}\right)\left(t_{1} / t_{2}\right)\right]^{1 / 2},
\]

где $t_{1}, t_{2}-$ средние времена ЭВМ, соответствующие выборкам $\xi, \eta$ (см., напр., [4]).

Если подинтегральная функция зависит от параметра, то целесообразно использовать ме то д 3 ав и с и м ы х и с п т а н и й, т. е. оценивать интегралы для различных значений параметра по одним и тем же случайным узлам [20]. Важным свойством М.-К. м. является сравнительно относительно слабая зависимость среднеквадратич. погрешности $\sigma_{N}$ от числа измерений, причем порядок сходимости по числу узлов $N$ всегда один и тот же: $N^{-1 / 2}$. Это позволяет оценивать (после предварительных преобразований задачи) интегралы очень высокой и даже бесконечной кратности. Напр., разработана методика оценки интегралов Винера [19].

А лгоритмы М.-К. м. для р ешени й ин-

![](https://cdn.mathpix.com/cropped/2023_07_08_4731fbedb794a52ac460g-1.jpg?height=44&width=829&top_left_y=1134&top_left_x=992)
Пусть необходимо оценить линейный функционал $\boldsymbol{J}_{\boldsymbol{h}}=(\varphi, h)$, где $\varphi=K \varphi+f$, причем для интегрального оператора $K$ с ядром $k\left(x^{\prime}, x\right)$ выполняется условие, обеспечивающее сходимость ряда Неймана: $\left\|K^{n_{0}}\right\|<1$. Цепь Маркова $\left\{x_{n}\right\}$ определяется начальной плотностью $\pi(x)$ и переходной плотностью $p\left(x^{\prime}, x\right)=p\left(x^{\prime} \rightarrow x\right)$; вероятность обрыва цепи в точке $x^{\prime}$ равна

\[
g\left(x^{\prime}\right)=1-\int p\left(x,{ }^{\prime} x\right) d x
\]

$N$ - случайный номер последнего состояния. Далее определяется функционал от траектории цепи, математич. ожидание к-рого равно $J_{h}$. Чаще всего используется т. н. оце н к по ст о лкн о е ния м

\[
\xi=\sum_{n=0}^{N} Q_{n} h\left(x_{n}\right)
\]

где

\[
Q_{0}=\frac{f\left(x_{0}\right)}{\pi\left(x_{0}\right)}, Q_{n}=Q_{n-1} \frac{k\left(x_{n-1}, x_{n}\right)}{p\left(x_{n-1}, x_{n}\right)} .
\]

Если $p\left(x^{\prime}, x\right) \neq 0$ при $k\left(x^{\prime}, x\right) \neq 0$ и $\pi(x) \neq 0$ при $f(x) \neq 0$, то при нек-ром дополнительном условии

\[
\mathrm{E} \xi=\sum_{n=0}^{\infty}\left(K^{n} f, h\right)=(\varphi, h)=\int_{X} \varphi(x) h(x) d x
\]

(см. [3]-[5]). Возможность достижения малой дисперсии в знакопостоянном случае показывает следующее утверждение: если

\[
\pi(x)=\frac{f(x) \varphi^{*}(x)}{\left(f, \varphi^{*}\right)} \text { и } p\left(x^{\prime}, x\right)=\frac{k\left(x^{\prime}, x\right) \varphi^{*}(x)}{\left[K^{*} \varphi^{*}\right]\left(x^{\prime}\right)},
\]

где $\varphi^{*}=K^{*} \varphi^{*}+h$, то $\mathrm{D} \xi=0$, а $\mathrm{E} \xi=J_{h}$ (см. [4]). Моделируя подходящую цепь Маркова на ЭВМ, получают статистич. оцөнки линейных функционалов от решения интегрального уравнения 2-го рода. Это дает возможность и локальной оценки решения на основе представления: $\uparrow(x)=\left(\varphi, h_{x}\right)+f(x)$, где $h_{x}\left(x^{\prime}\right)=k\left(x^{\prime}, x\right)$. В ряде случаев при решении таких задач наряду с М.-К. м. применяются теоретико-числовые методы (см. [21]).
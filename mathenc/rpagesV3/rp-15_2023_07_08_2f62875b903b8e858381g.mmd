функция $y(x)$ наз. регрессией величины $Y$ по $X$, a ee график - лин и е й р е г р е с с и и $Y$ по $X$. Зависимость $Y$ от $X$ проявляется в изменении средних значений $Y$ при изменении $X$, хотя при каждом фиксированном значении $X=x$ величина $Y$ остается случайной величиной с определенным рассеянием. Для выяснения вопроса, насколько точно регрессия передает изменение $Y$ при изменении $X$, используется условная дисперсия $Y$ при данном значении $X=x$ или ее средняя величина (мера рассеяния $Y$ около линии регрессии)

\[
\sigma_{\boldsymbol{Y} \mid \boldsymbol{X}}^{2}=\mathrm{E}[Y-\mathrm{E}(Y \mid X=x)]^{2} .
\]

Если $X$ и $\boldsymbol{Y}$ независимы, то все условные математич. ожидания $Y$ не зависят от $x$ и совпадают с безусловным: $y(x)=m_{Y}$, при этом $\sigma_{Y \mid X}^{2}=\sigma_{Y}^{2}$. При точной функциональной зависимости $Y$ от $X$ величина $Y$ при каждом данном $X=x$ принимает лишь одно определенное значение и $\sigma_{Y \mid X}^{2}=0$. Аналогично определяется $x(y)=\mathrm{E}[X \mid Y=$ $=y$ ] - регрессия $X$ по $Y$. Естественным показателем концентрации распределения вблизи линии регрессии $y(x)$ служит коррелячионное отношение

\[
\eta_{Y \mid X}^{2}=1-\sigma_{Y \mid X}^{2} / \sigma_{Y}^{2}
\]

Величина $\eta_{Y \mid X}^{2}=0$ тогда и только тогда, когда регрессия имеет вид $y(x)=m_{Y}$, в этом случае коэффициент $K . \rho$ равен 0 и величина $Y$ не коррелирована с $X$. Если регрессия $Y$ по $X$ линейна, т. е. линия регрессии-прямая

$y(x)=m_{Y}+\rho \frac{\sigma_{Y}}{\sigma_{X}}\left(x-m_{X}\right)$, то $\sigma_{Y \mid X}^{2}=\sigma_{Y}^{2}\left(1-\rho^{2}\right)$ и $\eta_{Y \mid X}^{2}=\rho^{2}$

если, кроме того, $|\rho|=1$, то $Y$ связана с $X$ точной линейной зависимостью, если же $\eta_{Y \mid X}^{2}=\rho^{2}<1$, то между $Y$ и $X$ нет функциональной зависимости. Точная функциональная зависимость $Y$ от $X$, отличная от линейной, имеет место тогда и только тогда, когда $\rho^{2}<\eta_{Y \mid X}^{2}=1$. Практическое использование коәффициента $\mathcal{~}$. в качестве меры отсутствия зависимости справедливо (за редким исключением) лишь тогда, когда совместное распределение $X$ и $Y$ нормально (или близко к нормальному распределению), так как в этом случае из равенства $\rho=0$ следует независимость $X$ и $Y^{\prime}$. Использование $\rho$ как меры зависимости для произвольных случайных величин $X$ и $Y$ приводит часто к ошибочным выводам, так как $\rho$ может равняться 0 даже при функциональной зависимости между величинами. Если двумерное распределение $X$ и $Y$ нормально, то обе линии регрессии суть прямые и $\rho$ полностью определяет концентрацию распределения вблизи линий регрессии: при $|\rho|=1$ прямые регрессии сливаются в одну, что соответствует линейной зависимости между $X$ и $Y$, при $\rho=0$ величины независимы.

При изучении связи между несколькими случайными величинами $X_{1}, \ldots, X_{n}$ с заданным совместным распределением пользуются множественными и частными корреляционными отношениями и коэфффициентами $K$. Последние вычисляются с помощью обычных коәффициентов $\kappa$. между $X_{i}$ и $X_{j}$, в совокупности образующих корреляционную матрицу. Мерой линейной связи между $X_{1}$ и совокупностью всех остальных величин $X_{2}, \ldots, X_{n}$ служит множественный коэфобициент корреляции. Если взаимосвязь величин $X_{1}$ и $X_{2}$ предположительно определяется влиянием остальных величин $X_{3}, \ldots, X_{n}$, то показателем линейной связи между $X_{1}$ и $\ddot{X}_{2}$ при исключении влияния $X_{2}, \ldots, X_{n}$ является частный коэфбициент корреляции $X_{1}$ и $X_{2}$ относительно $X_{2}, \cdots, X_{n}$. О мерах K., основанных на ранговых статистиках, см. ст. Кендалла коэббичиент ранговй корреляции, Спирмена коәффичиент ранговой корреляции.

В математич. статистике разработаны методы оценки коэфффициенто, характеризующих $К$. между случайными величинами или признаками, и методы проверки гипотез об их значениях, использующие их выборочные аналоги. Совокупность таких методов наз. к о р p eл я ц и о н н м а н а л и з о м. Корреляционный анализ статистич. данных заключает в себе следующие основные практич. приемы: 1) построение корреляционного поля и составление корреляционной таблицы; 2) вычисление выборочных корреляционных отношений или коэфффициентов К.; 3) проверка статистич. гипотезы значимости связи. Дальнейшее исследование может заключаться в установлении конкретного вида зависимости между величинами (см. Регрессия).

Вспомогательными средствами при анализе выборочных двумерных данных являются корреляционное поле и корреляционная таблица. При нанесении на координатную плоскость выборочных точек получают к о рр е л я ц и о н н о е п о л е. По характеру расположения точек поля можно составить предварительное мнение о форме зависимости случайных величин (напр., о том, что одна величина в среднем возрастает или убывает при возрастании другой). Для численной обработки результаты обычно группируют и представляют в форме ко р р е л я и о н н о й т а б л иц ы. В каждой клетке әтой таблицы приводятся численности $n_{i j}$ тех пар $(x, y)$, компоненты к-рых попадают в соответствующие интервалы группировки по каждой переменной. Предполагая длины интервалов группировки (по каждому из переменных) равными между собой, выбирают центры $x_{i}$ (соответственно $y_{i}$ ) этих интервалов и числа $n_{i j}$ в качестве основы для расчетов.

Более точную информацию о характере и силе связи, чем картина корреляционного поля, дают коэфффициент К. и корреляционное отношение. В ы б о р о ч ны й ко эффиц и е т к о р р ля ции определяется по формуле

\[
\hat{\rho}=\frac{\sum_{i} \sum_{j}\left(x_{i}-\bar{x}\right)\left(y_{j}-\bar{y}\right) n_{i j}}{\sqrt{\sum_{i} n_{i \cdot(}\left(x_{i}-\bar{x}\right)^{2}} \sqrt{\sum_{j} n_{\cdot j}\left(y_{j}-\bar{y}\right)^{2}}},
\]

где

\[
n_{i \cdot}=\sum_{j} n_{i j}, \quad n \cdot j=\sum_{i} n_{i j}
\]

$\mathbf{n}$

\[
\bar{x}=\frac{\sum_{i} n_{i} x_{i}}{n}, \bar{y}=\frac{\sum_{j} n_{\cdot j} y_{j}}{n} .
\]

При большом числе независимых наблюдений, подчиненных одному и тому же распределению, близкому к нормальному, $\hat{\rho}$ близок к истинному коәффициенту К. $\dot{\rho}$. Во всех других случаях в качестве характеристики силы связи рекомендуется использовать корреляционное отношение, интерпретация к-рого не зависит от вида исследуемой зависимости. Выборочное значение $\hat{\eta}_{Y \mid X}^{2}$ вычисляется по данным корреляционной таблицы:

\[
\hat{\eta}_{Y \mid X}^{2}=\frac{\frac{1}{n} \sum_{i} n_{i \cdot(}\left(\bar{y}_{i}-\bar{y}\right)^{2}}{\frac{1}{n} \sum_{j}^{n_{\cdot j}\left(y_{j}-\bar{y}\right)^{2}}}
\]

где числитель характеризует рассеяние условных средних значений $\bar{y}_{i}$ около безусловного среднего $\bar{y}$ (аналогично определяется выборочное значение $\hat{\eta}_{\boldsymbol{X} \mid \boldsymbol{Y}}^{2}$ ). Величина $\hat{\eta}_{Y \mid X}^{2}-\hat{\rho}^{2}$ используется в качестве индикатора отклонения регрессии от линейной.
4) $C(t, t)=I$

5) $|C(t, s)| \leqslant \exp \int_{s}^{t}|A(r)| d r, s \leqslant t$,

где $|\cdot|$-норма в $\mathbb{R}^{n}$;

6) если $H(t, s)$-матрица Коши сопряженной системы

\[
\dot{x}=-A^{*}(t) x
\]

то

\[
H(t, s)=\left[C^{*}(t, s)\right]^{-1}
\]

Лит.: [1] Б у р б а к и Н., Функции действительного переменного. Элементарная теория, пер. с франц., М., 1965; [2] Г а н тм а х е p Ф. Р., Теория матриц, 2 изд., М., 1966; [3] Д е м и д ов и ч Б. П., Лекции по математической теории устойчивости, М., 1967; [4] Я к у бо в и ч В. А., С т а р жин с к и й В. М.,
Линейные дифференциальные уравнения с периодическими коәффициентами и их приложения, М., 1972. Ю. В. Комленко.

МАТРИЧНАЯ ГРУППА - группа квадратных $(n \times n)$-матриц с әлементами из ассоциативного кольца с единицеї относительно обычного умножения матриц. См. Линейная әруппа.

МАТРИЧНАЯ ИГРА - антагонистическая игра, в к-роӥ каждый игрок имеет конечное число чистых стратегий. Если игрок I имеет $m$ стратегий, а игрок II имеет $n$ стратегиї, то М. и. может быть задана $(m \times n)$ матрицей $A=\left\|a_{i j}\right\|$, где $a_{i j}, i=1, \ldots, m, j=1, \ldots, n$, есть выигрыш игрока I, если он выбирает стратегию $i$, а игрок II - стратегию $j$. Согласно общему принципу оптимальности в антагонистич. играх (см. также $M и н и-$ макса принцип), игрок I стремится выбрать такую стратегию $i_{0}$, на к-рой достигается

\[
\max _{i} \min _{j} a_{i j}=\underline{v}
\]

a игрок II стремится выбрать стратегию $j_{0}$, на к-рой достигается

\[
\min _{j} \max _{i} a_{i j}=\bar{v}
\]

ЕсліІ $v=\bar{v}$, то пара $\left(i_{0}, j_{0}\right)$ составляет седловую точку игры; число $a_{i_{0} j_{0}}$ есть значение игры, а стратегии $i_{0}, j_{0}$ суть оптимальные чистые стратегии. Если $\underline{v} \neq \bar{v}$ (т. е. решения в чистых стратегиях нет), то всегда $\underline{v}<\bar{v}$. В этом случае оптимальные стратегии игроков следует искать среди их смешанных стратегий. Пусть $X \subset \mathbb{R}^{m}$ (соответственно $Y \subset \mathbb{R}^{n}$ ) - множество смешанных стратегий игрока I (соответственно игрока II). Тогда игрок I будет стремиться к стратегии $x^{*}$, на к-рой достигается

\[
\underline{v}^{*}=\max _{x \in X} \min _{y \in Y} x A y^{\top},
\]

a игрок II - к стратегии $y^{*}$, на к-рой достигается $\overline{v^{*}}=\min _{y \in Y} \max _{x \in X} x A y^{\top}$

(симвплом ${ }^{\top}$ обозначено транспонирование). Основная теорема теории М. и. (т е о р е м а Н е й м а н а о м и н и м а к с е) утверждает, что $v^{*}=\overline{v^{*}}=v$, т. е. для любой М. и. существуют оптимальные смешанные стратегиіI $x^{*}, y^{*}$ и значение игры $v$.

Для чи сленн ого ре шения М. и. (т. е. нахожденія оптимальных стратегий и значения игры) чаще всего используют возможность сведения М. и. к задаче линейного программирования. Менее әффективен пттеративный м е т о д Б р а у н а - Р о б и нс о н, к-рый состоит в фиктивном "разыгрывании" M. и., причем игроки на каждом шаге выбирают наилучшие чистые стратегии в условиях «накопленной» смешанной стратегии противника. М. и., в к-рых один из игроков имеет только две стратегии, просто решаются графич. методом.

M. I. могут служить математич. моделями многих простейпих конфликтных ситуаций из области экономикі, математич. статистики, военного дела, биологии. В приложениях в качестве одного из игроков нередко рассматривают «природу», под к-рой понимается вся совокупность внешних обстоятельств, неизвестных принимаюшему решение лицу (другому игроку).

Лит.: [1] Матричные игры. Сб. статей, М., 1961; [2] Н е йм а н Д ж., М о р ге нш т е рн О., Теория игр и әкономическое поведение, пер. с англ.; М., 1970; [3] о у ән г., Теория игр, пер. с англ., М., 1971; [4] В о р о б ь е в Н. Н., Теория
игр. Лекции для әкономистов-кибернетиков, Л., 1974.

МАТРИЧНОЕ ДИФФЕРЕНЦИАЛЬНОЕ $\stackrel{ }{\text { А. }}$ РАВНЕНИЕ - уравнение, неизвестной в к-ром является функциональная матрица, входящая в уравнение вместе со своей производной.

Пусть рассматривается линейное М. Д. У. вида

\[
X^{\prime}=A(t) X, \quad t \in \mathbb{R},
\]

где $A(t)$ есть $(n \times n)$-матрица-функция с локально интегрируемыми по Лебегу әлементами, и пусть $X(t)-$ абсолютно непрерывное решение уравнения (1), удовлетворяющее условию $X\left(t_{0}\right)=I, I-$ единичная матрица. Тогда вектор-функция $x(t)=X(t) h, h \in \mathbb{R} n$, является решением линейной системы

\[
x^{\prime}=A(t) x,
\]

удовлетворяющим условию $x\left(t_{0}\right)=h$. Обратно, если $h_{1}, \ldots, h_{n} \in \mathbb{R}^{n}$ и $x_{i}(t)$ - решение системы $(2)$, удовлетворяющее условию $x_{i}\left(t_{0}\right)=h_{i}, i=1, \ldots, n$, то функциональная матрица $X(t)$, столбцами к-рой служат решения $x_{i}(t)$, является решением М. Д. у. (1). Если при этом векторы $h_{1}, \ldots ., h_{n}$ линейно независимы, то $\operatorname{det} X(t) \neq 0$ при всех $t \in \mathbb{R}$.

Уравнение (1) является частным случаем следующего М. Д. у. (возникающего в теории устойчивости)

\[
X^{\prime}=A(t) X-X B(t)+C(t) .
\]

Решение М. Д. У. (3) с начальным условием $X\left(t_{0}\right)=X_{0}$ дается равенством

$X(t)=U\left(t, t_{0}\right) X_{0} V\left(t, t_{0}\right)+\int_{t_{0}}^{t} U(t, s) C(s) V(s, t) d s$, где $U(t, s)$ - рецшение М. д. у. (1) с условием $X(s, s)=$ $=I$, а $V(t, s)$ - решение М. д. У. $X^{\prime}=B(t) X$ с условием $X(s, s)=I$.

В различных прикладных задачах (теории стабилизации, оптимального управления, фильтрации управляемых систем и др.) большую роль играет т. н. м а тричное дифффе ренциальное ур авнени е Р ик к а т и

\[
X^{\prime}=A(t) X-X B(t)+C(t)+X D(t) X .
\]

Напр., если матричное уравнение Риккати

\[
\begin{gathered}
X^{\prime}=-(F(t)+\lambda I)^{\top} X-X(F(t)+\lambda I)-I+ \\
+X G(t) G^{\top}(t) X,
\end{gathered}
\]

где ${ }^{T}$ означает транспонирование, имеет при $\lambda \geqslant 0$ ограниченное на прямой $\mathbb{R}$ решение $X(t)$ и для всех $h \in \mathbb{R} n$, всех $t \in \mathbb{R}$ и нек-рого $\varepsilon>0$ выполнено неравенство $h^{\top} X(t) h \geqslant \varepsilon h^{\top} h$, то любое решение управляемой системы

\[
x^{\prime}=F(t) x+G(t) u, x \in \mathbb{R}^{n}, u \in \mathbb{R}^{m},
\]

замкнутоӥ обратной связью $u=-\frac{1}{2} G^{\top}(t) X(t) x$, удовлетворяет неравенству

\[
|x(t)| \leqslant M|x(s)| \exp [-\lambda(t-s)], s \leqslant t,
\]
ложнений, к-рые могут ждать его при построении статистич. оценок, так как Н. о. может оказаться как очень хорошей, так и совершенно бессмысленной, она может быть неединственной, а может вовсе не существовать. Кроме того, Н. о., как и всякая точечная оценка, обладает еще следующим недостатком: она дает лишь нек-рое приближенное значение для истинного значения оцениваемой величины, к-рое как было неизвестным до эксперимента, таковым и остается после его проведения. Вообще, в задаче построения точечных статистич. оценок нет серьезных обоснований к тому, ттобы во всех случаях стремиться к получению Н. о., если не считать того, что при изучении Н. о. возникает простая и стройная теория. Так, напр., Рао- Крамера неравенство имеет простой вид для Н. о. Именно, если $T=T(X)-$ Н. о. для функции $f(\theta)$, то при довольно широких условиях регулярности семейства $\left\{\mathrm{P}_{\theta}\right\}$ и функции $f(\theta)$ из неравенства Рао- Крамера следует, что

\[
\mathrm{D}\{T\}=\mathrm{E}\left\{[T-f(\theta)]^{2}\right\} \geqslant \frac{1}{I(\theta)} f^{\prime}(\theta),
\]

где $I(\theta)$ - информационное количество Фишера. Таким образом, существует нижняя граница для дисперсий Н. о. функции $f(\theta)$, и этой границей служит $f^{\prime}(\theta) / I(\theta)$. В частности, если $f(\theta) \equiv \theta$, то из (1) следует, тTо

\[
\mathrm{D}\{T\} \geqslant 1 / I(\theta) \text {. }
\]

Статистич. оценка, для к-рой в неравенстве РаоКрамера достигается равенство, наз. ә ф ф е к т и вн о й. Так, статистика $T=X / n$, рассмотренная в примере 5 , является әффективной $Н$. о. параметра усшеха $\theta$ биномиального закона, т. к.

\[
\mathrm{D}\{T\}=\frac{1}{n} \theta(1-\theta)
\]

и

\[
I(\theta)=\mathrm{E}\left\{\left[\frac{\partial}{\partial \theta} \ln \left[\theta^{X}(1-\theta)^{n-X}\right]\right]^{2}\right\}=\frac{n}{\theta(1-\theta)},
\]

т. е. $T=X / n$ является наилучшей точечной оценкой параметра в смысле минимума квадратичного риска в классе всех Н. о.

Естественно, что для әкспериментатора представляет интерес тот случай, когда класс Н. о. достаточно богат, чтобы иметь возможность выбора наилучшей в какомто смысле Н. о. В этой связи большую роль играет Рао - Блэкуәлла - Колмогорова теорема, позволяющая строить Н. о. с наименьшей дисперсией. Эта теорема утверждает, что если семейство $\left\{\mathrm{P}_{\theta}\right\}$ имеет достаточную статистику $\Psi=\Psi(X)$, а $T=T(X)-$ произвольная Н. о. функции $f(\theta)$, то статистика $T^{*}=$ $=\mathrm{E}_{\theta}\{T \mid \Psi\}$, получаюгцаяся в результате осреднения $T$ при фиксированной достаточной статистике $\Psi$, имеет риск, не превосходящий риска статистики $T$ относительно произвольной выпуклой функции потерь при всех $\theta \in \Theta$. Е.сли при этом семейство $\left\{P_{\theta}\right\}$ является полным, то статпстика $T^{*}$ определяется единственным образом. То есть из теоремы Рао - Бләкуэлла - Колмогорова следует, что Н. о. нужно искать лишь в терминах достаточных статистик, если они существуют. Практич. ценность теоремы Рао - Бләкуәлла - Колмогорова заключается в том, что она дает рецепт построения наилучших Н. о., а именно: нужно построить произвольную Н. о. для $f(\theta)$, а затем осреднить ее но достаточной статистике.

$\Pi$ р и е р 6. Пусть случайная величина $X$ имеет распределение Паскаля (отрицательное биномиальное распределение) с параметрами $r$ и $\theta(r \geqslant 2,0 \leqslant \theta \leqslant 1)$, т. е.

\[
\mathrm{P}\{X=k \mid r, \theta\}=\left(\begin{array}{c}
r+k-1 \\
k
\end{array}\right) \theta^{r}(1-\theta)^{k}, k=r, r+1, \ldots
\]

В этом случае статистика $T=(r-1) /(X-1)$ является Н. о. параметра $\theta$. Так как статистика $T$ выражена в терминах достаточной статистики $X$, а система функций $1, x, x^{2}, \ldots$ является полной на отрезке $[0,1]$, то $T$ являе'ся единственной Н. о., а следовательно, наилучшей оценкой для $\theta$.

П р и м е р 7. Пусть $X$ - случайная величина, подчиняющаяся биномиальному закону с параметрами $n$ и $\theta$. Производящая функция $Q(z)$ әтого биномиального закона выражается формулой

\[
Q(z)=\mathrm{E}\left\{z^{X}\right\}=(z \theta+q)^{n}, \quad q=1-\theta,
\]

откуда следует, что для любого целого числа $k=1,2$, $\cdots, n$

\[
\begin{gathered}
Q^{(k)}(z)=n(n-1) \ldots(n-k+1)(z \theta+q)^{n-k} \theta^{k}= \\
=n^{[k]}(z \theta+q)^{n-k} \theta^{k} .
\end{gathered}
\]

С другой стороны,

$Q^{(k)}(1)=\mathrm{E}\{X(X-1) \ldots(X-k+1)\}=\mathrm{E}\left\{X^{[k]}\right\}$, откуда следует, что

\[
E\left\{\frac{1}{n^{[k]}} X^{[k]}\right\}=\theta^{k}
\]

т. е. статистика

\[
T_{k}(X)=\frac{1}{n^{[k]}} X^{[k]}
\]

является Н. о. для $\theta^{k}$, причем в силу того, что $T_{k}(X)$ выражена в терминах достаточной статистики $X$, a также в силу полноты системы функций $1, x, x^{2}, \ldots$ на отрезке $[0,1]$ следует, что $T_{k}(X)$ - единственная, а значит, и наплучшая Н. о. для $\theta^{k}$.

В связи с этим примером возникает следующий вопрос: какие функции $f(\theta)$ от параметра $\theta$ допускают несмещенное оценивание. А. Н. Колмогоров показал [1], что только для многочленов степени $m \leqslant n$ существуют Н. о. Так, если

\[
f(\theta)=a_{0}+a_{1} \theta+\ldots+a_{m} \theta^{m}, \quad 1 \leqslant m \leqslant n,
\]

то из (2) следует, что статистика

\[
T=a_{0}+\sum_{k=1}^{m} a_{k} T_{k}(X)
\]

является единственной Н. о. для $f(\theta)$. Из этого результата, в частности, следует, что для функции $f(\theta)=1 / \theta$ не существует Н. о.

$\Pi$ р и м е р 8. Пусть $X-$ случайная величина, подчиняющаяся закону Пуассона с параметром $\theta$, т. е. для любого целого числа $k=0,1,2, \ldots$

\[
\mathrm{P}\{X=k \mid \theta\}=\frac{\theta^{k}}{k !} e^{-\theta}, \quad \theta>0 .
\]

В силу того, что $\mathrm{E}\{X\}=\theta$, само наблюдение $X$ является Н. о. своего математич. ожидания $\theta$. В свою очередь, напр., Н. о. функции $f(\theta)=\theta^{2}$ является $X(X-1)$. Вообце, статистика

\[
X^{[r]}=X(X-1)(X-2) \ldots(X-r+1), \quad r=1,2, \ldots,
\]

является Н. о. функции $f(\theta)=\theta r$. Из этого факта, в частности, следует, что статистика

\[
T(X)=1+\sum_{r=1}^{\infty}(-1)^{r} X^{[r]}
\]

является Н. о. функции $f(\theta)=(1+\theta)^{-1}, 0<\theta<1$. Вообще, если функция $f(\theta)$ допускает несмещенное оценивание, то для нее должно выполняться уравнение несмещенности $E\{T(X)\}=f(\theta)$, к-рое равносильно следующему:

\[
\sum_{k=0}^{\infty} T(k) \frac{\theta^{k}}{k !} e^{-\theta}=f(\theta)
\]
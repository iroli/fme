В случае, когда величины $\xi$ и $\eta$ принимают конечное число значений, выражение для И. к. $I(\xi, \eta)$ приобретает следующий вид:

\[
I(\xi, \eta)=\sum_{i=1}^{n} \sum_{j=1}^{m} p_{i j} \log \frac{p_{i j}}{p_{i} q_{i}},
\]

где

\[
\left\{p_{i}, i=1, \ldots, n\right\},\left\{q_{j}, j=1, \ldots, m\right\},
\]

$\left\{p_{i j}, i=1, \ldots, n ; j=1, \ldots, m\right\}-$ распределения вероятностей $\xi, \eta$ и пары $(\xi, \eta)$ соответственно (в частности,

\[
I(\xi, \xi)=-\sum_{i=1}^{n} p_{i} \log p_{i}=H(\xi)
\]

является энтропией случайной величины $\xi$ ), а если $\xi$, $\eta$ - случайные векторы и существуют плотности $p_{\xi}(x), p_{\eta}(y), p_{\xi \eta}(x, y)$ случайных векторов $\xi, \eta$ и пары $(\xi, \eta)$ соответственно, то

\[
I(\xi, \eta)=\int p_{\xi \eta}(x, y) \log \frac{p_{\xi \eta}(x, y)}{p_{\xi}(x) p_{\eta}(y)} d x d y .
\]

В общем случае

\[
I(\xi, \eta)=\sup I(\varphi(\xi), \psi(\eta))
\]

где верхняя грань берется по всем измеримым функциям $\varphi(\cdot)$ и $\psi(\cdot)$ с конечным числом значений. Понятие И. к. используется главным образом в теории передачи инфорормации.

Лит. см. [1], [2], [4] при ст. Информачии передача.

ИНФОРМАЦИИ ПЕРЕДАЧА информачии теории, относящаяся к изучению процесса переноса информации от источника сообщений к получателю сообщений (адресату). В теории И. П. изучаются оптимальные и близкие к оптимальным методы И. п. по каналам связи в предположении, что можно в пироких пределах варьировать методы кодирования сообщений в сигналы на входе канала и декодирования сигналов на выходе канала в сообщения на выходе (см. Кодирование и декодирование).

Общую схему системы И. п., впервые рассмотренную K. IIенноном (C. Shannon, [1]), можно описать следующим образом. Источник сообщений вырабатывает сообщения, подлежащие передаче по каналу связи от источника к получателю. Обычно предполагают, что это сообение - случайная величина $\xi$, определенная на нек-ром вероятностном пространстве $(\Omega, \mathfrak{A}$, $P)$, принимающая значения в нек-ром измеримом пространстве ( $\left.\mathfrak{X}, S_{\mathfrak{X}}\right)$ и имеющая распределение вероятностей $p(\cdot)$. Часто $\xi=\{\xi(t), t \in \Delta\}$, где $\Delta-$ множество значений параметра $t$, является случайным процессом с дискретным или непрерывным временем со значениями в нек-ром измеримом пространстве $\left(X, S_{X}\right)$. Напр., в случае дискретного времени $\xi=\left\{\xi_{k}, k=1,2, \ldots\right\}$ или $\xi=\left\{\xi_{k}, k=\ldots,-1,0,1, \ldots\right\}$ случайные величины $\xi_{k}$, принимающие значения в измеримом пространстве $\left(X, S_{X}\right)$, наз. компонентами сообения на входе и часто трактуются как сообщения, вырабатываемые источником в моменты времени $k$. Наборы $\xi^{n=}$ $=\left(\xi_{1}, \ldots, \xi_{n}\right)$, принимающие значения в пространстве

![](https://cdn.mathpix.com/cropped/2023_07_08_51fa81623ba11e7c1ad8g-1.jpg?height=37&width=829&top_left_y=1981&top_left_x=119)
$\left(X, S_{X}\right)$, наз. отрезками сообщений длины $n$ на входе. Аналогичным образом определяются соответствующие понятия и в случае, когда сообщение - случайный ıроцесс с непрерывным временем.

Сообщение на выходе, получаемое адресатом,- это тоже случайная величина $\tilde{\xi}$, определенная на том же вероятностном пространстве $(\Omega, \mathfrak{A}, P)$ и принимающая значения в измеримом пространстве $\left(\tilde{\mathfrak{X}}, S_{\tilde{\mathfrak{X}}}\right)$ (вообще говоря, отличном от $\left.\left(\mathfrak{X}, S_{\mathfrak{X}}\right)\right)$. В случае, когда ляется случайным процессом с дискретным или непрерывным временем, аналогичным образом вводятся понятия пространства $\left(\tilde{X}, S_{\tilde{X}}\right)$ значений компонент сообщения на выходе и пространства $\left(\tilde{X}^{n}, S_{\tilde{X}^{n}}\right)$ значений отрезков длины $n$ сообщения на выходе.

Мерой качества передачи сообщений по каналу связи является сообщений точность воспроизвеения. Как правило, если передача ведется по каналу связи с помехами, даже если множества $\mathfrak{X}$ и $\tilde{\mathfrak{X}}$ совпадают, нельзя добиться абсолютной точности, т. е. полного совпадения посылаемого и получаемого сообпений. Обычно требования, предъявляемые к точности, трактуют статистически, выделяя класс $W$ допустимых совместных распределений вероятностей для пары $(\xi, \bar{\xi})$ передаваемого и получаемого сообшений в множестве всех вероятностных мер в произведении $\left(\mathfrak{X} \times \tilde{\mathfrak{F}}, S_{\mathfrak{X}} \times S_{\tilde{\mathfrak{X}}}\right)$. Класс $W$ часто задается при помощи измеримой неотрицательной функции $\rho(x, \tilde{x}), x \in \mathfrak{X}, \tilde{x} \in \tilde{\mathfrak{F}}$, и числа $a>0:$ считают, что распределение вероятностей $(\xi, \xi)$ принадлежит $W$, лишь если

\[
\mathbf{E} \rho(\xi, \tilde{\xi}) \leqslant a .
\]

Таким образом, условие точности воспроизведения показывает, насколько полученное сообщение может отличаться от переданного.

Сообщения, вырабатываемые источником, передаются по каналу связи. К а н а л о м $(Q, V)$ наз. совокуп-

![](https://cdn.mathpix.com/cropped/2023_07_08_51fa81623ba11e7c1ad8g-1.jpg?height=45&width=838&top_left_y=1089&top_left_x=985)
переходной функции $Q(y, A), y \in \mathfrak{R}, A \in S_{\tilde{\mathfrak{Y}}}$, являющейся измеримой относительно б-алгебры $S_{\mathfrak{Y}}$ при фиксированном $A \in S_{\mathfrak{\eta}}$ и вероятностной мерой на $\left(\tilde{\mathfrak{X}}, S_{\tilde{\mathfrak{Y}}}\right)$ при фиксированном $y \in \mathfrak{R}, \quad$ и подмножества $V$ в пространстве всех вероятностных мер в пространстве

![](https://cdn.mathpix.com/cropped/2023_07_08_51fa81623ba11e7c1ad8g-1.jpg?height=49&width=836&top_left_y=1315&top_left_x=986)
ветственно пространствами сигналов на входе и выходе канала, а подмножество $V$ - ограничением на распределение сигнала на входе. Говорят, что две случайные величины $\eta$ и $\tilde{\eta}$ (определенные на вероятностном пространстве $(\Omega, \mathfrak{A}, P))$ связаны каналом $(Q, V)$,

![](https://cdn.mathpix.com/cropped/2023_07_08_51fa81623ba11e7c1ad8g-1.jpg?height=47&width=834&top_left_y=1515&top_left_x=987)
соответственно и для любого $A \in S_{\tilde{\mathfrak{Y}}}$ с вероятностью 1 условная вероятность

\[
\mathrm{P}\{\tilde{\eta} \in A \mid \eta\}=Q(\eta, A)
\]

и распределение вероятностей случайной величины $\eta$ принадлежит $V$. Наиболее часто ограничение $V$ задается с помощью измеримой функции $\pi(y), \quad y \in \mathfrak{M}$, и числа $b>0$ : считают, что распределение вероятностей $\eta$ принадлежит $V$, лишь если

\[
\mathbf{E} \boldsymbol{\pi}(\eta) \leqslant b
\]

В случае дискретных каналов $V$ обычно совпадает с совокупностью всех распределений вероятностей, т. е. ограничение отсутствует.

C наглядной точки зрения, ֵㅜ - это совокупность сигналов, передаваемых передатчиком, а $\tilde{2}$ - совокупность сигналов, принимаемых приемником (в приложениях пространства $\mathfrak{S}$ и $\tilde{\mathfrak{B}}$ часто совпадают). Если задано случайное значение $\eta$ сигнала на входе, то (2) позволяет найти условное распределение сигнала на выходе $\tilde{\eta}$. Введение ограничения $V$ связано с тем, что во многих приложениях нельзя считать распределение входного сигнала произвольным [типична, напр., ситуация, когда предполагается, что среднее значение квадрата (мощность) входного сигнала не превосходит
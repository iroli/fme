заданной константы]. В приложениях особенно важен случай, когда сигналами на входе и выходе канала являются случайные процессы $\eta=\{\eta(t)\}, \tilde{\eta}=\{\tilde{\eta}(t)\}$ с дискретным или непрерывным временем, определенные на нек-ром конечном или бесконечном (в одну или обе стороны) интервале действительной оси и принимающие значения в нек-рых измеримых пространствах $\left(Y, S_{Y}\right)$ и $\left(\tilde{Y}, S_{\tilde{Y}}\right)$ соответственно. Напр., если $\eta=$ $=\left\{\eta_{1}, \eta_{2}, \ldots\right\}$ и $\tilde{\eta}=\left\{\tilde{\eta}_{1}, \tilde{\eta}_{2}, \ldots\right\}-$ случайные последовательности, то канал связи, для к-рого последовательности $\eta$ и $\eta$ служат сигналами на входе и выходе, часто рассматривают как последовательность каналов (в описанном выше смысле), называемых отрезками данного канала; сигналами на входе и выходе этих отрезков канала служат векторы

\[
\eta^{n}=\left(\eta_{1}, \ldots, \eta_{n}\right) \text { и } \tilde{\eta}^{n}=\left(\tilde{\eta}_{1}, \ldots, \tilde{\eta}_{n}\right), n=1,2, \ldots
\]

Для того чтобы превратить сообщение на входе в сигнал, передаваемый по каналу связи, а сигнал, полученный на выходе канала,- в сообщение на выходе, необходимо провести операции кодирования и декодирования сообщений. К о д и р о в а н и е м наз. функцию $f(x)$ от $x \in \mathfrak{X}$ со значениями в $\mathfrak{M}$, а д е к од и р о в а н и е м - функцию $\tilde{g}(y)$ от $\tilde{y} \in \tilde{\mathbb{R}}$ со значениями в $\tilde{\mathfrak{X}}$. Множество значений функции $f(x), x \in \mathfrak{X}$, часто наз. к о д о м, а отдельные элементы этого множества - к о д о в ы м и с л о в а м и. Использование кодирования $f(x)$ и декодирования $g(\tilde{y})$ означает, что если сообщение приняло значение $x \in \mathfrak{X}$, то по каналу передается сигнал $y=f(x)$; если на выходе канала получен сигнал $\tilde{y} \in \tilde{\mathfrak{D}}\}$, то его декодируют в сообщение на выходе $\tilde{x}=g(\tilde{y})$. В теории передачи информации часто рассматривают с луч а й н о е коди р о в а н ие, когда кодовые слова выбираются случайно в соответствии с нек-рым распределением вероятностей.

Сообщение с распределением вероятностей $p(\cdot)$, вырабатываемое источником, может быть передано с точностью воспроизведения $W$ по каналу $(Q, V)$ при помощи кодирования $f(\cdot)$ и декодирования $g(\cdot)$, если могут быть построены случайные величины $\xi, \eta, \tilde{\eta}$, $\tilde{\xi}$, образующие цепь Маркова такую, что $\xi$ имеет распределение вероятностей $p(\cdot)$, распределение вероятностей пары $(\xi, \tilde{\xi})$ принадлежит $W$. пара $(\eta, \tilde{\eta})$ связана каналом $(Q, V)$ и

\[
\eta=f(\xi), \quad \xi=g(\vec{\eta}) .
\]

Предположение о том, что $\xi, \eta, \tilde{\eta}, \tilde{\xi}$ образуют цепь Маркова, сводится к предположению о том, что условное распределение $\tilde{\eta}$ при заданных значениях $\xi$ и $\eta$ зависит лишь от $\eta$, т. е. оно означает, что при передаче сигнал на выходе зависит лишь от сигнала на входе, а не от того, какое значение сообщения им закодировано.

Основную проблему, исследуемую в И. п., можно сформулировать следующим образом. Считаются известными и фиксированными источник, порождающий сообщения с распределением вероятностей $p(\cdot)$, канал связи $(Q, V)$ и условия точности воспроизведения $W$. Задача состоит в том, чтобы выяснить, при каких условиях существуют методы кодирования $f(\cdot)$ и декодирования $g(\cdot)$ такие, что сообщение, вырабатываемое данным источником, может быть передано с заданной точностью воспроизведения $W$ по данному каналу $(Q, V)$. Решения этой проблемы при разных предположения наз. теоремами кодирования, или теоремами IÏенона. Естественно возникает также другая проблема о том, как в случае, когда передача возможна, построить наиболее простым и әфффективным образом кодирование и декодирование, осуществляющие эту передачу.

К. IIеннон [1] ввел величины, позволяющие сформулировать ответ на первую из поставленных проблем. Главной среди них является информации количество, или просто информация, $I(\cdot, \cdot)$. Если

\[
C=C(Q, V)=\sup I(\eta, \tilde{\eta})
\]

- пропускная способность канала $(Q, V)$ (см. Канала пропускная способность), где верхняя грань берется по всем парам величин ( $\eta, \tilde{\eta})$, связанным каналом $(Q, V)$, и если число

\[
H_{W}(p)=\inf I(\xi, \tilde{\xi})
\]

есть $W$-энтропия (см. Энтропия) сообщения, где ниж-

![](https://cdn.mathpix.com/cropped/2023_07_08_31eac9f8b1d7398d4167g-1.jpg?height=44&width=831&top_left_y=643&top_left_x=994)
совместное распределение вероятностей пары $(\xi, \tilde{\xi})$ принадлежит $W$, а $\xi$ имеет распределение вероятностей $p(\cdot)$, то справедлива следующая теорема Шеннона (обращение теоремы кодирования): если сообщение с распределением вероятностей $p(\cdot)$ может быть передано по каналу $(Q, V)$ с условием точности воспроизведения $\boldsymbol{W}$, то

\[
H_{W}(p) \leqslant C(Q, V) .
\]

Достаточные условия для возможности И. п. получить сложнее. Так, условие (7) достаточно для возможности И. п. лишь в некотором асимптотич. смысле, и при этом главным является предположение о том, что $H_{W}(p) \rightarrow \infty$, следовательно условие (7) необходимо и достаточно лишь, грубо говоря, применительно к задаче о передаче довольно большого количества информации. Остальные нужные предположения носят характер предположений регулярности, к-рые в конкретных ситуациях обычно выполняются. Чтобы сформулировать достаточные условия для возможности передачи в точных терминах, необходимы нек-рые дополнительные понятия.

Последовательность пар случайных величин $\left(\zeta^{t}, \tilde{\zeta}\right.$, $t=1,2, \ldots)$ наз. информационно-устойчивой, если $0<I\left(\zeta^{t}, \tilde{\zeta}^{t}\right)<\infty \quad$ и

\[
\lim _{t \rightarrow \infty} \frac{i_{\xi} t \bar{\zeta}^{t}\left(\xi^{t}, \tilde{\zeta}^{t}\right)}{I\left(\xi^{t}, \bar{\zeta}^{t}\right)}=1
\]

в смысле сходимости по вероятности. Здесь $i_{\zeta} t_{\xi} t(\cdot, \cdot)$ информационная плотность (см. Информации количество) пары $\left(\zeta^{t}, \tilde{\zeta}^{t}\right)$. Последовательность каналов $\left\{\left(Q^{t}, V^{t}\right), t=1,2, \ldots\right\}$ с $C\left(Q^{t}, V^{t}\right)<\infty$ наз. информационно-устойчивой, если существует информационноустойчивая последовательность пар $\left(\eta^{t}, \tilde{\eta}^{t}\right)$, связанных каналом $\left(Q^{t}, V^{t}\right)$, такая, что

\[
\lim _{t \rightarrow \infty} \frac{I\left(\eta^{t}, \eta^{t}\right)}{C\left(Q^{t}, \nabla^{t}\right)}=1 .
\]

Последовательность сообщений с распределением вероятностей $p^{t}(\cdot)$ и условиями точности $W^{t}$ с $H_{W} t\left(p^{t}\right)<$ $<\infty, t=1,2, \ldots$, наз. информационно-устойчивой, если существует последовательность пар $\left(\xi_{t}, \tilde{\xi} t\right)$ такая, что $\xi^{t}$ имеет распределение вероятностей $p^{t}(\cdot)$, распределение вероятностей пары $\left(\xi^{t}, \tilde{\xi}^{t}\right)$ принадлежит $W^{t}$ и

\[
\lim _{t \rightarrow \infty} \frac{I\left(\xi^{t}, \tilde{\xi}^{t}\right)}{H_{W}{ }^{t}\left(p^{t}\right)}=1 .
\]

Пусть $V_{\varepsilon}-$ множество распределений вероятностей, для к-рого справедливо (3) с заменой $b$ на $b+\varepsilon$, a $W_{\varepsilon}-$ условие точности, задаваемое неравенством (1), в к-ром
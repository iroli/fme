рые задачи теории чисел (см., напр., [5]) равносильны задачам теории представлений, связанных с Д. с. групп аделей линейных алгебраич. групп.

Лum.: [1] Ге ль ф а н д И. М., Н а й м а p к Унитарные представления классических групп, М., 1950; [2]
$\Gamma$ р и н л ф Ф., Инвариантные средние на топологических группах и их іриложения, пер. с англ., М., 1973; [3] Н а й м а р к М. А., Линейные представления группы Лоренца, М., 1958; [4] K o c т a н т Б., "Математика", 1970, т. 14, №2, c. 102-16; 23-67. A. И. Штерн.

ДОПУСТИМОЕ ПРАВИЛО - вывода правило, добавление к-рого в исчисление не меняет объема выводимых в этом исчислении слов. Введение в исчисление Д. п. является мощным и часто применяемым средством сокращения выводов, во многіх случаях полезно для совершенствования алгоритмов установления выводимости. Одним из важнейших результатов математич. логики является теорема о допустимости правила сөчения (см. Генцена бормальная система). См. Выводимое правило, Производное правило.

ДОСТАТОЧНАЯ СТАТИСТИКА для семейства распределений вероятностей $\left\{p_{\theta} ; \theta \in \Theta\right\}$ или для параметра $\theta \in \Theta$ - статистика (векторная случайная величина) такая, что для любого события $A$ существует вариант условной вероятности $P_{\theta}(A \mid X=x)$, не зависящий от $\theta$. Это эквивалентно требованию, что условное распределение любой другой статистики $Y$ при условии $X=x$ не зависит от $\theta$.

Знание Д. с. $X$ дает исчерпывающий материал для статистич. выводов о параметре $\theta$, поскольку любые дополнительные статистич. данные ничего не добавляют к той информации о параметре, к-рая содержится в распределении $X$. Математич. выражением этого свойства является один из результатов теории статистич. решений, утверждающий, что множество решающих правил, основанных на Д. с., образует существенно полный класс. Переход от исходного семейства распределений к семейству распределений Д. с. наз.

![](https://cdn.mathpix.com/cropped/2023_07_08_577114e276e159485f49g-1.jpg?height=34&width=826&top_left_y=1288&top_left_x=123)
Смысл редукции заключается в уменьшении (часто весьма значительном) размерности пространства наблюдений.

Практический способ нахождения Д. с. основан на следующей теореме факторизации. Пусть семейство

![](https://cdn.mathpix.com/cropped/2023_07_08_577114e276e159485f49g-1.jpg?height=43&width=828&top_left_y=1462&top_left_x=122)
$=d P_{\theta} / d \mu-$ плотность распределения $P_{\theta}$ относительно меры $\mu$. Статистика $X$ достаточна для семейства $\left\{P_{\theta}\right\}$ в том и только в том случае, когда

\[
p_{\theta}(\omega)=g_{\theta}(X(\omega)) h(\omega)
\]

где $g_{\theta}, h$ - неотрицательные измеримые функции ( $h$ не зависит от $\theta$ ). Для дискретных распределений в качестве $\mu$ можно взять «считающую" меру: в этом случае $p_{\theta}(\omega)$ в соотношении (\%) имеет смысл вероятности элементарного события $\{\omega\}$.

Пусть, напр., $X_{1}, \ldots, X_{n}$ - последовательность независимых случайных величин, принимающих значение 1 с неизвестной вероятностью $v$ и значение 0 с вероятностью 1-v (схема Бернулли). Тогда

\[
\begin{gathered}
p_{v}\left(x_{1}, \ldots, x_{n}\right)= \\
=\prod_{i=1}^{n} v^{x_{i}}(1-v)^{1-x_{i}}=v^{\sum_{i=1}^{n} x_{i}}(1-v)^{n-\sum_{i=1}^{n} x_{i}}
\end{gathered}
\]

Равенство (*) выполняется, если положить

\[
X=\sum_{i=1}^{n} X_{i}, \quad g_{6}=p_{\theta}, \quad h=1 .
\]

Таким образом, эмпирическая частота

\[
\hat{v}=\frac{1}{n} \sum_{i=1}^{n} X_{i}
\]

является Д. с. для неизвестной вероятности $v$ в схеме Бернулли.

Пусть $X_{1}, \ldots, X_{n}$ - последовательность независимых нормально распределенных величин с неизвестными средним значением $\mu$ и дисперсией $\sigma^{2}$. Совместная плотность распределения $X_{1}, \ldots, X_{n}$ по мере Лебега дается выражением

\[
\begin{aligned}
& p_{\mu, \sigma^{2}}\left(x_{1}, \ldots, x_{n}\right)=\left(2 \pi \sigma^{2}\right)^{-n / 2} \times \\
& \times \exp \left[-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}\right]=
\end{aligned}
\]

$=\left(2 \pi \sigma^{2}\right)^{-n / 2} \exp \left(-\frac{n \mu^{2}}{2 \sigma^{2}}-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n} x_{i}^{2}+\frac{\mu}{\sigma^{2}} \sum_{i=1}^{n} x_{i}\right)$,

зависящим от $x_{1}, \ldots, x_{n}$ только через величины

\[
\sum_{i=1}^{n} x_{i}, \quad \sum_{i=1}^{n} x_{i}^{2}
\]

Поэтому векторная статистика

\[
X=\left(\sum_{i=1}^{n} X_{i}, \quad \sum_{i=1}^{n} X_{i}^{\mathbf{2}}\right)
\]

является Д. с. для двумерного параметра $\theta=\left(\mu, \sigma^{2}\right)$. Д. с. здесь будет и совокупность выборочного среднего

\[
\hat{\mu}=\frac{1}{n} \sum_{i=1}^{n} X_{i}
\]

и выборочной дисперсии

\[
\hat{\sigma}^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(X_{i}-\hat{\mu}\right)^{2},
\]

поскольку величины

\[
\sum_{i=1}^{n} X_{i}, \quad \sum_{i=1}^{n} X_{i}^{2}
\]

могут быть выражены через $\hat{\mu}$ и $\hat{\sigma}^{2}$.

Для одного и того же семейства распределений может существовать много Д. с. В частности, тривиальной Д. с. является совокупность всех наблюдений [в рассмотренных выше примерах $\left.\left(X_{1}, \ldots, X_{n}\right)\right]$. Однако основной интерес представляют статистики, позволяющие осуществить действительную редукцию статистич. задачи. Д. с. наз. м и н и м а л ь н о й, или нео бх о д м о й, если она есть функция от любой другой Д. с. Необходимая Д. с. осуществляет максимально возможную редукцию статистич. задачи. В рассмотренных примерах найденные Д. с. являются необходимыми.

Важное применение понятия достаточности - метод улучшения несмещенных оценок, основанный на т е ор е м $\mathrm{P}$ а о- Б л э к у э л а в а: если $X-$ Д. с. для семейства $\left\{P_{\theta}\right\}, X_{1}$ - произвольная статистика, принимающая значения в векторном пространстве $\mathbb{R}^{d}$, то для действительной непрерывной выпуклой функции $g$ на $\mathbb{R}^{d}$

\[
\mathbf{E}_{\theta} g\left(X_{1}-\mathrm{E}_{\theta}\left(X_{1}\right)\right) \geqslant \mathrm{E}_{\theta} g\left(\hat{X}_{1}-\mathbf{E}_{\theta}\left(\hat{X}_{1}\right)\right), \quad \theta \in \Theta,
\]

где $\hat{X}_{1}=\mathrm{E}_{\theta}\left(X_{1} \mid X\right)$ - условное математич. ожидание статистики $X_{1}$ относительно $X$ (к-рое фактически не зависит от $\theta$ в силу достаточности $X)$. В качестве функции потерь $g$ здесь часто берется положительно определенная квадратичная форма на $\mathbb{R} d$.

Статистика $X$ наз. п о лн о й, если равенство $\mathrm{E}_{\theta} f(X) \equiv 0, \quad \theta \in \Theta$, влечет $f(X)=0$ почти наверное относительно $P_{\theta}, \theta \in \Theta$. Одно из следствий теоремы Рао - Блэкуэлла - Колмогорова утверждает, что если существует полная Д. с. $X$, то она является равномерно по $\theta$ наилучшей несмещенной оценкой своего математич. ожидания $e(\theta)=\mathrm{E}_{\theta} X$. Подобная ситуация имеет место в приведенных примерах. Так, әмпирическая частота $\hat{v}$ является равномерно наилучшей не-
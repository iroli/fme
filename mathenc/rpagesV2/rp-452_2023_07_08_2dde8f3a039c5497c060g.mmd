и при $i=j$ совпадают с $\mathrm{D} X_{i}$ (т. е. на главной диагонали К. м. находятся дисперсии величин $X_{i}$ ). К. м. представляет собой симметричную неотрицательно определенную матрицу. Если К. м. является положительно определенной, то распределение $X$ - невырожденное распределение, в противном случае - вырожденное. Для случайного вектора $X$ К. м. играет роль дисперсии. Если дисперсии случайных величин $X_{1}, \ldots, X_{k}$ равны 1, то с корреляционной матрицей.

Выборочная К. м. для выборки $X^{(1)}, \ldots, X^{(n)}$, где $X^{(m)}, \quad m=1, \ldots, n$ - независимые одинаково распределенные случайные $k$-мерные векторы, состоит из оценок дисперсий и ковариаций:

\[
S=\frac{1}{n-1} \sum_{m=1}^{n}\left(X^{(m)}-\bar{X}\right)\left(X^{(m)}-\bar{X}\right)^{T},
\]

где $\bar{X}$ - вектор ариф্фметического среднего $X^{(1)}, \ldots$, $X^{(n)}$. Если случайные векторы $X^{(1)}, \ldots, X^{(n)}$ имеют нормальное распределение с К. м. $\Sigma$, то $S$ является оценкой максимального правдоподобия $\Sigma$; в этом случае совместное распределение элементов матрицы $(n-1) S$ наз. Уищарта распределением, оно является одним из основных распределений в многомерном статистич. анализе, с помощью к-рого проверяются гипотезы о K. м. $\Sigma$. A. В. Прохоров.

КОВАРИАЦИОННЫЙ АНАЛИЗ - совокупность методов математич. статистики, относящихся к анализу моделей зависимости среднего значения нек-рой случайной величины $Y$ от набора неколичественных факторов $F$ и, одновременно, от набора количественных факторов $x$. По отношению к $Y$ переменные $x$ наз. с о п у т с т в у ю щ и м и; факторы $F$ задают сочетания условий качественной природы. при к-рых получены наблюдения $Y$ и $x$, и описываются с помощью так наз. и н д и к а т о р ны $\mathbf{x}$ переменных; среди сопутствующих и индикаторных переменных могут быть как случайные, так и не случайные (контролируемые в эксперименте); если случайная величина $Y$ является вектором, то говорят о многомерном $\mathrm{K}$. а.

Основные теоретические и прикладные проблемы К. а. относятся к линейным моделям. В частности, если анализируется схема из $n$ наблюдений $Y_{1}, \ldots$, $Y_{n}$ с $p$ сопутствующими переменными и $k$ возможными типами условий эксперимента, то линейная модель соответствующего К. а. задается уравнениями

\[
\begin{gathered}
Y_{i}=\sum_{j=1}^{k} f_{i j} \theta_{j}+\sum_{s=1}^{p} \beta_{s}\left(F_{i}\right) x_{i}^{(s)}+\varepsilon_{i}\left(F_{i}\right), \\
i=1, \ldots, n,
\end{gathered}
\]

где индикаторные переменные $f_{i j}$ равны 1 , если $j$-е условие эксперимента имело место при наблюдении $Y_{i}$, и равны 0 в ином случае; коэфффициенты $\theta_{j}$ определяют әффект влияния $i$-го условия; $x_{i}^{(s)}-$ значение сопутствующей переменной $x^{(s)}$, при к-рой получено наблюдение $Y_{i}, \quad i=1, \ldots, n ; s=1, \ldots, p ; \beta_{s}\left(F_{i}\right)-$ значения соответствующих коәфффициентов регрессии $Y$ по $x^{(s)}$, вообще говоря, зависящие от конкретного сочетания условий эксперимента, т. е. от вектора $F_{i}=$ $=\left(f_{i 1}, \ldots, f_{i k}\right) ; \varepsilon_{i}\left(F_{i}\right)$ - случайные опибки, имеющие нулевые средние значения. Основное содержание К. а.в построении статистич. оценок для неизвестных параметров $\theta_{1}, \ldots, \theta_{k} ; \beta_{1}, \ldots, \beta_{p}$ и статистич. критериев для проверки различных гипотез относительно значений этих параметров.

Если в модели $(*)$ постулировать априори $\beta_{1}=\ldots=$ $=\beta_{p}=0$, то получится модель дисперсионного анализа; если из $(*)$ исключить влияние неколичественных факторов (положить $\theta_{1}=\ldots=\theta_{k}=0$ ), то получится модель регрессионного анализа. Своим названием К. а. обязан тому обстоятельству, что в его вычислениях исполь- зуются разбиения ковариации величин $Y$ и $X$ точно так же, как в дисперсионном анализе используются разбиения суммы квадратов отклонений $Y$.

Лит.: [1] Ш е ф ф е Г., Дисперсионный анализ, пер. с англ., М., 1963; [2] К е н д а л л М. ДІ ж., С т ь ю а р т А., Многом., 1976; [3] «Вiometrics», 1957, v. 13, № 3. С.. А. Айвазлн.
М.

КОВАРИАЦИЯ - числовая характеристика совместного распределения двух случайных величин, равная математич. ожиданию произведения отклонений случайных величин от их математич. ожиданий. $К$. определяется для случайных величин $X_{1}$ и $X_{2}$ с конечными дисперсиями и обычно обозначается $\operatorname{cov}\left(X_{1}, X_{2}\right)$. Таким образом,

\[
\operatorname{cov}\left(X_{1}, X_{2}\right)=\mathrm{E}\left[\left(X_{1}-\mathrm{E} X_{1}\right)\left(X_{2}-\mathrm{E} X_{2}\right)\right],
\]

при этом $\operatorname{cov}\left(X_{1}, X_{2}\right)=\operatorname{cov}\left(X_{2}, X_{1}\right) ; \operatorname{cov}(X, X)=\mathrm{D} X$. К. естественным образом появляется в выражении для дисперсии суммы случайных величин

\[
\mathrm{D}\left(X_{1}+X_{2}\right)=\mathrm{D} X_{1}+\mathrm{D} X_{2}+2 \operatorname{cov}\left(X_{1}, X_{2}\right) \text {. }
\]

Если величины $X_{1}$ и $X_{2}$ независимы, то cov $\left(X_{1}, X_{2}\right)=$ $=0$. К. служит характеристикой взаимозависимости случайных величин, с помощью К. определяется корреляции коэффициент. В математич. статистике оценкой Н. служит выборочная К., вычисляемая по формуле

\[
\frac{1}{n-1} \sum_{i=1}^{n}\left(X_{1}^{(i)}-\bar{X}_{1}\right)\left(X_{2}^{(i)}-\bar{X}_{2}\right)
\]

где $\left(X_{1}^{(i)}, X_{2}^{(i)}\right), i=1, \ldots, n$, - независимые величины, а $\overline{X_{1}}$ и $\overline{X_{2}}$ - арифметические средние. $А$. В. Прохоров.

КОВАРИАЦИЯ ЧИСЛА РЕІІЕНИЙ - ПоняТИе В дисперсионном методе, вводимое при сравнении чисел решений уравнений

$\mathbf{I}$

\[
n=\varphi+D^{\prime} v
\]

\[
n=\psi+D^{\prime} v
\]

где $\varphi$ и $\psi$ принадлежат к некоторым последовательностям натуральных чисел, $D^{\prime}$ пробегает некоторую заданную систему чисел сегмента

\[
(D)=\left[D_{1}, D_{1}+D_{2}\right]
\]

$v$ пробегает систему чисел сегмента

\[
(v)=\left[v_{0}, v_{0}+v_{0}^{\prime}\right]
\]

Пусть

\[
U_{1}(m)=\sum_{\varphi=m} 1, \quad U_{2}(m)=\sum_{\psi=m} 1,
\]

тогда дисперсия разности решений уравнений (1) и (2) будет

\[
V^{\prime}=\sum_{D^{\prime} \in(D)}\left(\sum_{1}^{\prime}-\sum_{2}^{\prime}\right)^{2}
\]

где

$\Sigma_{1}^{\prime}=\sum_{v \in(v)} U_{1}\left(n-D^{\prime} v\right), \quad \sum_{2}^{\prime}=\sum_{v \in(v)} U_{2}\left(n-D^{\prime} v\right)^{2}$.

Применяя идею И. М. Виноградова по сглаживанию двойных сумм, можно распространить суммирование по $\mathrm{D}^{\prime}$ на все $D$ из $(D)$. Дисперсия при этом может только увеличиться; таким образом

где

\[
V^{\prime} \leqslant V=V_{1}-2 V_{2}+V_{3} \text {, }
\]

\[
\begin{gathered}
V_{1}=\sum_{D \in(D)}\left(\sum_{1}\right)^{2}, \\
V_{3}=\sum_{D \in(D)}\left(\sum_{2}\right)^{2}, \\
V_{2}=\sum_{D \in(D)}\left(\sum_{1} \sum_{2}\right)
\end{gathered}
\]
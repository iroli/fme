Истинные значения функций $\alpha, \beta_{i}, \gamma_{j}$ и $\delta_{i j}$ неизвестны и выражаются в терминах неизвестных функций $c_{i j}$. Поэтому первый этап Д. а. заключается в отыскании статистич. оценок для $c_{i j}$ по результатам наблюдений $x_{i j k}$. Несмещенная и имеющая минимальную дисперсию линейная оценка для $c_{i j}$ выражается формулой

\[
\hat{c}_{i j}=x_{i j *}=\frac{1}{K} \sum_{k} X_{i j k} .
\]

Так как $\alpha, \beta_{i}, \gamma_{j}$ и $\delta_{i j}$ - линейные функции от элементов матрицы $\left\|c_{i j}\right\|$, то несмещенные линейные оценки для этих функций, имеющие минимальную дисперсию, получаются в результате замены аргументов $c_{i j}$ соответствующими оценками, $\hat{c}_{i j}$, т. е.

\[
\begin{gathered}
\hat{\alpha}=x_{* * * *}, \quad \hat{\beta}_{i}=x_{i * * *}-x_{* * *}, \quad \hat{\gamma}_{j}=x_{* j_{*}}-x_{* * *}, \\
\hat{\delta}_{i j}=x_{i j *}-x_{i * *}-x_{* j_{*}}+x_{* * * * *},
\end{gathered}
\]

причем случайные векторы $\left(\hat{\alpha}_{i j}\right),\left(\hat{\beta}_{i j}\right),\left(\hat{\gamma}_{i j}\right)$ и $\left(\hat{\delta}_{i j}\right)$, определенные так же, как введенные выше $\left(\alpha_{i j}\right),\left(\beta_{i j}\right)$, $\left(\gamma_{i j}\right)$ и $\left(\delta_{i j}\right)$, обладают свойством ортогональности, и значит, они представляют собой некоррелированные случайные векторы (иными словами, любые две компоненты, принадлежащие разным векторам, имеют нулевой коэффициент корреляции). Кроме того, любая разность вида

\[
x_{i j k}-x_{i j_{*}}=x_{i j k}-\hat{c}_{i j}
\]

некоррелирована с любой из компонент этих четырех векторов. Рассмотрим пять совокупностей случайных величин $\left\{x_{i j k}\right\},\left\{x_{i j k}-x_{i j *}\right\},\left\{\hat{\beta}_{i}\right\},\left\{\hat{\gamma_{j}}\right\}$ и $\left\{\hat{\delta}_{i j}\right\}$. Так как

\[
\begin{gathered}
x_{i j k}-x_{i j_{*}}=y_{i j k}-y_{i j_{*}}, \quad \hat{\beta}_{i}=\beta_{i}+\left(y_{i * *}-y_{* * *}\right), \\
\hat{\gamma}_{j}=\gamma_{j}+\left(y_{* j_{*}}-y_{* * *}\right), \\
\hat{\delta}_{i j}=\delta_{i j}+\left(y_{i j_{*}}-y_{i * *}-y_{* j_{*}}+y_{* * *}\right),
\end{gathered}
\]

то дисперсии эмпирич. распределений, соответствующих указанным совокупностям, выражаются формулами

\[
\begin{gathered}
S^{2}=\frac{1}{I J K} \sum_{i j k}\left(x_{i j k}-x_{* * *}\right)^{2} \\
S_{0}^{2}=\frac{1}{I J K} \sum_{i j k}\left(x_{i j k}-x_{i j *}\right)^{2}=\frac{1}{I J K} \sum_{i j k}\left(y_{i j k}-y_{i j_{*}}\right)^{2} \\
S_{1}^{2}=\frac{1}{I} \sum_{i} \hat{\beta}_{i}^{2}=\frac{1}{I} \sum_{i}\left[\beta_{i}+\left(y_{i * *}-y_{* * *}\right)\right]^{2} \\
S_{2}^{2}=\frac{1}{J} \sum_{j} \hat{\gamma}_{i}^{2}=\frac{1}{J} \sum_{j}\left[\gamma_{j}+\left(y_{* j *}-y_{* * *}\right)\right]^{2}
\end{gathered}
\]\[
S_{3}^{2}=\frac{1}{I J} \sum_{i j} \widehat{\delta}_{i j}^{2}=\frac{1}{I J} \sum_{i j}\left[\delta_{i j}+\left(y_{i j *}-y_{i * *}-y_{* j_{*}}+y_{* * *}\right)\right]^{2} .
\]

Эти эмпирич. дисперсии представляют собой суммы квадратов случайных величин, любые две из к-рых некоррелированы, если только они принадлежат разным суммам; при этом относительно всех $y_{i j k}$ справедливо тождество

\[
S^{2}=S_{0}^{2}+S_{1}^{2}+S_{2}^{2}+S_{3}^{2}
\]

объясняющее происхождение термина «Д. а.».

Пусть $I, J, K \geqslant 2$ и пусть

\[
\begin{gathered}
s_{0}^{2}=\frac{K}{K-1} S_{0}^{2}, \quad s_{1}^{2}=\frac{I J K}{I-1} S_{1}^{2}, \quad s_{2}^{2}=\frac{I J K}{J-1} S_{2}^{2}, \\
s_{3}^{2}=\frac{I J K}{(I-1)(J-1)} S_{3}^{2},
\end{gathered}
\]

в таком случае

$E s_{0}^{2}=\sigma^{2}, \quad E s_{1}^{2}=\sigma^{2}+\frac{J K}{I-1} \sum_{i} \beta_{i}^{2}, \quad E s_{2}^{2}=\sigma^{2}+\frac{I K}{J-1} \sum_{j} \gamma_{j}^{2}$,

\[
E s_{3}^{2}=\sigma^{2}+\frac{K}{(I-1)(J-1)} \sum_{i j} \delta_{i j}^{2},
\]

где $\sigma^{2}$ - дисперсия случайных ошибок $y_{i j k}$. На основе этих формул и строится второй этап Д. а., посвященный выявлению влияния первого іг второго факторов на результаты эксперимента (в агрономич. опытах первый фактор - copт «почвы», второй - способ «обработки»). Напр., если требуется проверіть гипотезу отсутствия «взаимодействия» факторов, к-рая выражается равенством $\sum_{i j} \delta_{i j}^{2}=0$, то разумно вычислить д и с п е р с и онно е о т н о шени е $s_{\mathbf{3}}^{2} / s_{0}^{2}=F_{3}$. Если это отношение значимо отличается от единицы, то проверяемая гипотеза отвергается. Точно так же для проверки гипотезы $\sum_{j} \gamma_{j}^{2}=0$ полезно отношение $s_{2}^{2} / s_{0}^{2}=F_{2}$, к-рое надлежит также сравнить с единицей; еслі при этом известно, что $\sum_{i j} \delta_{i j}^{2}=0$, то вместо $F_{2}$ целесообразно сравнить с единицей отношение

\[
\frac{(I J K-I-J-1) s_{2}^{2}}{I J(K-1) s_{0}^{2}+(I-1)(J-1) s_{3}^{2}}=F_{2}^{*} .
\]

Аналогичным образом можно постролть статистику, позволяющую дать заключение о справедливости или ложности гипотезы $\sum_{i} \beta_{i}^{2}=0$.

Точный смысл понятия значимого отличия указанных отношений от единицы может быть определен лишь с учетом закона распределения случайных ошшбок $y_{i j k}$. В Д. а. наиболее обстоятельно изучена ситуація, в к-рой все $y_{i j k}$ распределены нормально. В этом случае $\left(\hat{\alpha}_{i j}\right),\left(\beta_{i j}\right),\left(\hat{\gamma}_{i j}\right),\left(\delta_{i j}\right)$ - независимые случайные векторы, а $s_{0}^{2}, s_{1}^{2}, s_{2}^{2}, s_{3}^{2}-$ независимые случайные велічіны, причем отношения

\[
\begin{gathered}
I J(K-1) \frac{s_{0}^{2}}{\sigma^{2}}, \quad(I-1) \frac{s_{1}^{2}}{\sigma^{2}}, \quad(J-1) \frac{s_{2}^{2}}{\sigma^{2}}, \\
(I-1)(J-1) \frac{s_{3}^{2}}{\sigma^{2}}
\end{gathered}
\]

подчиняются нецентральным распределениям хи-квадрат с $f_{m}$ степенями свободы и параметрами нецентральности $\lambda_{m}, m=0,1,2,3$, где

$f_{0}=I J(K-1), f_{1}=I-1, f_{2}=J-1, f_{3}=(I-1)(J-1)$;

\[
\begin{gathered}
\lambda_{0}=0, \quad \lambda_{1}=J K \sum_{i} \beta_{i}^{2} / \sigma^{2}, \quad \lambda_{2}=I K \sum_{j} \gamma_{j}^{2} / \sigma^{2}, \\
\lambda_{3}=K \sum_{i j} \delta_{i j}^{2} / \sigma^{2} .
\end{gathered}
\]

Если параметр нецентральности равен нулю, то нецентральное распределение хи-квадрат совпадает с обычным распределением хи-квадрат. Поэтому в случае справедливости гипотезы $\lambda_{3}=0$ отношение $s_{3}^{2} / s_{0}^{2}=F_{3}$ подчиняется $F$-распределению (распределению дисперсіонного отношения) с параметрами $f_{3}$ и $f_{0}$. Пусть $x-$ такое число, для к-рого вероятность события $\left\{F_{3}>x\right\}$ равна заданному значению $\varepsilon$, называемому у р о в н е м 3 н а ч им о с т и (таблицы функции $x=x\left(\varepsilon ; f_{3}, f_{0}\right)$ имеются в большинстве пособий по математич. статистике). Критерием для проверки гипотезы $\lambda_{3}=0$ служит правпло, согласно к-рому эта гипотеза отвергается, если наб́людаемое значение $F_{3}$ превышает $x$; п противном случає гипотеза считается не противоречащей результатам наблюдений. Аналогичным образом конструируются критерии, основанные на статистиках $F_{2}$ и $F_{2}^{*}$.

Дальнейшие этапы Д. а. существенно завпсят не только от реального содержания конкретной задачII, но также и от результатов статистич. проверки гіпотез на втором этапе. Напр., в условиях агрономич. опытов справедливость гипотезы $\dot{\lambda}_{3}=0$, как указано выше, позволяет более экономно спланировать аналогічные дальнейшие эксперименты (если помимо гипотезы $\lambda_{3}=0$ справедлива также и гипотеза $\lambda_{2}=0$, то это означает, что урожайность зависит лишь от сорта «почвы», ІІ поэтому в дальнейших опытах можно воспользоваться схемой
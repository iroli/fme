{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Базовый парсер заголовков\n",
    "\n",
    "Вытаскивает из latex-кода заголовки статей и их расположение в файлах.\n",
    "\n",
    "Разбивка происходит в полуручном режиме, т.к. нет уверенности в формате заголовков.\n",
    "\n",
    "В тексте ищутся слова, содержащие в своём составе заглавные буквы на русском и английском языках в отношении, большем или равным заданному (по умолчанию 0.51, при меньших значениях количество вхождений значительно возрастает, например за счёт двухбуквенных предлогов). Предполагается, что таким образом удаётся обнаруживать неправильно машиинно распознанный капс. Слова или цепочки слов, состоящие из одного строчного символа включаются в заголовок, если стоят между слов, определённых как часть заголовка. При этом, одиночные заглавные буквы, а также инициалы не воспринимаются как начало заголовка.\n",
    "\n",
    "## Использование\n",
    "- При удовлетворительном определении заголовка нажать `Enter` без дополнительного ввода.\n",
    "- Если предложенное место заголовком не является ввести `\"n\"`\n",
    "- При неправильном определении границ заголовка ввести два корректировочных числа для сдвига левой и правой границы.\n",
    "  - ЗАМЕЧАНИЕ: сдвиг производится попробельно, т.е. двойной пробел будет распознан как слово нулевой длины.\n",
    "  - ЗАМЕЧАНИЕ: границы отображаемого фрагмента текста будут передвинуты автоматически. Длины левой и правой границ в словах задаются в параметрах.\n",
    "  - ПРИМЕРЫ:\n",
    "    - `out: a [B C] d e f` -> `in: 0 2` -> `out: a [B C D E] f`\n",
    "    - `out: a b c [D E] f` -> `in: 2 -1` -> `out: a [B C D] e f`\n",
    "- Также возможен посимвольный сдвиг правой границы в случае \"сращивания\" заголовка статьи и её текста. Ввести одно число, начиная с точки.\n",
    "  - ПРИМЕРЫ:\n",
    "    - `out: a[BC]def` -> `in: .2` -> `out: a[BCDE]f`\n",
    "    - `out: a[BCDE]f` -> `in: .-1` -> `out: a[BCD]ef`\n",
    "\n",
    "В выводе в терминале переносы строк для удобства заменены на `\"$\"`\n",
    "\n",
    "### Прочее\n",
    "- Для определителя капса достуны исключения, которые никогда не будут рассматриваться, как потенциальные начала заголовков, см. опции. По умолчанию: первые 10 римских цифр, \"МэВ\" и \"ГэВ\".\n",
    "- Использовать системный терминал для взаимодействия оказывается удобнее, чем использовать jupyter, поэтому можно скопировать ячейку с кодом в файл `scripter.py` и запускать его.\n",
    "- При положительном определении заголовка файл дополняется немедленно, прервать процесс можно в любой момент, как и продолжить после -- итоговый файл будет дополяться, а не перезаписываться с нуля при новом запуске программы (главное не забыть предварительно удалить из конца файла дубликаты, если вы начинаете с той страницы, на которой закончили в прошлый раз, а не со следующей)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "\n",
    "############################ VARS ################################\n",
    "PAGES_DIR = \"./matphys/rpages/\"\n",
    "EXIT_DIR = \"./matphys/\"\n",
    "EXIT_FILE = \"FMEv2.xml\"\n",
    "# First and last pages to be parsed\n",
    "START_PAGE = 225\n",
    "END_PAGE = 300\n",
    "# How many words to display before and after a potential title\n",
    "LEAD_WORDS = 5\n",
    "AFT_WORDS = 5\n",
    "# Look in the description\n",
    "CAPS_QUOT = 0.51\n",
    "EXCEPTIONS = ['I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X', 'МэВ', 'ГэВ']\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\n",
    "class Article:\n",
    "\tstart_title = 0\n",
    "\tend_title = 0\n",
    "\tfilename = ''\n",
    "\n",
    "\n",
    "\n",
    "# Write xml tree to file\n",
    "def prettify(elem):\n",
    "\t# Pretty-printed XML string for the Element.\n",
    "\trough_string = ET.tostring(elem, 'utf-8')\n",
    "\treparsed = minidom.parseString(rough_string)\n",
    "\treturn reparsed.toprettyxml(indent=\"  \")\n",
    "def xml_write(root):\n",
    "\twith codecs.open(EXIT_DIR + EXIT_FILE, 'w', 'utf-8') as f:\n",
    "\t\tf.write(prettify(root))\n",
    "\n",
    "\n",
    "# Get filenames needed\n",
    "filenames_raw = next(walk(PAGES_DIR), (None, None, []))[2]  # [] if no file\n",
    "filenames = []\n",
    "for i in range(START_PAGE, END_PAGE + 1):\n",
    "\tfor filename in filenames_raw:\n",
    "\t\tbeginning = \"rp-\" + str(i) + \"_\"\n",
    "\t\tif filename[:len(beginning)] == beginning and filename[-4:] == \".mmd\":\n",
    "\t\t\tfilenames.append(filename)\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "# Check for existing xml\n",
    "filenames_raw = next(walk(EXIT_DIR), (None, None, []))[2]  # [] if no file\n",
    "if not(EXIT_FILE in filenames_raw):\n",
    "\troot = ET.Element('data')\n",
    "\txml_write(root)\n",
    "\n",
    "\n",
    "def remove_xml_spaces(elem):\n",
    "\telem.tail = None\n",
    "\tif elem.text != None:\n",
    "\t\tis_space = True\n",
    "\t\tfor letter in elem.text:\n",
    "\t\t\tis_space = False if letter != ' ' else is_space\n",
    "\t\telem.text = None if is_space else elem.text\n",
    "\tfor subelem in elem:\n",
    "\t\tsubelem = remove_xml_spaces(subelem)\n",
    "\treturn elem\n",
    "def parse_xml():\n",
    "\t# Parse existing xml (string parsing is needed to avoid extra newlines appearing)\n",
    "\texit_string = ''\n",
    "\twith codecs.open(EXIT_DIR + EXIT_FILE, 'r', 'utf-8') as f:\n",
    "\t\tfor i in f.readlines():\n",
    "\t\t\texit_string += i[:-1]\n",
    "\troot = ET.fromstring(exit_string)\n",
    "\t# Remove empty tails and texts\n",
    "\troot = remove_xml_spaces(root)\n",
    "\treturn root\n",
    "root = parse_xml()\n",
    "num = len(root) + 1\n",
    "\n",
    "\n",
    "# Add article title and metadata to xml tree\n",
    "def add_artice(elem, root, num):\n",
    "\tarticle = ET.SubElement(root, 'article', {'n':str(num)})\n",
    "\ttitle = ET.SubElement(article, 'title')\n",
    "\ttitle.text = file[elem.start_title+1:elem.end_title]\n",
    "\ttitle_meta = ET.SubElement(article, 'title-meta')\n",
    "\ttitle_file = ET.SubElement(title_meta, 'title-file')\n",
    "\ttitle_file.text = elem.filename\n",
    "\ttitle_start = ET.SubElement(title_meta, 'title-start')\n",
    "\ttitle_start.text = str(elem.start_title + 1)\n",
    "\ttitle_end = ET.SubElement(title_meta, 'title-end')\n",
    "\ttitle_end.text = str(elem.end_title)\n",
    "\txml_write(root)\n",
    "\n",
    "\n",
    "# Count number of alphabetic letters in word\n",
    "def count_letters(word):\n",
    "\tnum = 0\n",
    "\tfor letter in word:\n",
    "\t\tnum += 0 if re.match(r\"[A-ZА-Яa-zа-я]\", letter) == None else 1\n",
    "\treturn num\n",
    "\n",
    "# Check if word is written in CAPS\n",
    "def check_caps(word):\n",
    "\tnum = 0\n",
    "\tlen_word = 0\n",
    "\tfor letter in word:\n",
    "\t\t#num += 0 if re.match(r\"[A-ZА-Я0-9]|[!#$%&'*+-.^_`|~:]\", letter) == None else 1\t\t\t\t\t# Too many symbols, math formulas are being detected\n",
    "\t\tlen_word += 1 if re.match(r\"[!#$%&'*+-.^_`|~:]\", letter) == None else 0\n",
    "\t\tnum += 0 if re.match(r\"[A-ZА-Я]\", letter) == None else 1\n",
    "\treturn 0 if len_word == 0 or num / len_word < CAPS_QUOT or word in EXCEPTIONS else num\t\t\t\t# Also exclude common roman numbers\n",
    "\n",
    "# Check for initials like \"I.E.\"\n",
    "def check_initials(word):\n",
    "\tinitials = True\n",
    "\tfor i in range(len(word) - 1):\n",
    "\t\ttype_1 = 0 if re.match(r\"[A-ZА-Яa-zа-я]\", word[i]) == None else 1\n",
    "\t\ttype_2 = 0 if re.match(r\"[A-ZА-Яa-zа-я]\", word[i + 1]) == None else 1\n",
    "\t\tinitials = False if type_1 and type_2 else initials\n",
    "\treturn initials\n",
    "\n",
    "\n",
    "# Find next ot prev word boundary (space / newline)\n",
    "def prev_from(pos, file):\n",
    "\tpos = max(pos, 0)\n",
    "\tprev_space = file.rfind(' ', 0, pos)\n",
    "\tprev_nl = file.rfind('\\n', 0, pos)\n",
    "\tprev_space = -1 if prev_space == -1 else prev_space\n",
    "\tprev_nl = -1 if prev_nl == -1 else prev_nl\n",
    "\treturn max(prev_nl, prev_space)\n",
    "def next_from(pos, file, end_replace = True):\n",
    "\tnext_space = file.find(' ', pos + 1)\n",
    "\tnext_nl = file.find('\\n', pos + 1)\n",
    "\tif end_replace:\n",
    "\t\tnext_space = len(file) if next_space == -1 else next_space\n",
    "\t\tnext_nl = len(file) if next_nl == -1 else next_nl\n",
    "\treturn max(next_nl, next_space) if next_space == -1 or next_nl == -1 else min(next_nl, next_space)\n",
    "\n",
    "\n",
    "# Main loop\n",
    "for filename in filenames:\n",
    "\tprint()\n",
    "\tprint(\"################################ \" + filename + \" ################################\")\n",
    "\twith codecs.open(PAGES_DIR + filename, 'r', 'utf-8') as f:\n",
    "\t\tfile = f.read()\n",
    "\t\n",
    "\tword_bound_l = -1\n",
    "\tword_bound_r = next_from(word_bound_l, file, end_replace=False)\n",
    "\tEOF_reached = False\n",
    "\n",
    "\twhile not EOF_reached:\n",
    "\t\tif word_bound_r == -1:\n",
    "\t\t\tword_bound_r = len(file)\n",
    "\t\t\tEOF_reached = True\n",
    "\n",
    "\n",
    "\t\tif check_caps(file[word_bound_l+1:word_bound_r]) < 2 or check_initials(file[word_bound_l+1:word_bound_r]):\n",
    "\t\t\tword_bound_l = word_bound_r\n",
    "\t\t\tword_bound_r = next_from(word_bound_l, file, end_replace=False)\n",
    "\t\t\n",
    "\t\telse: # Possibly found a title\n",
    "\t\t\t# Left border of a title is already known\n",
    "\t\t\tstart_title = word_bound_l\n",
    "\n",
    "\t\t\t# Define right border of a title\n",
    "\t\t\tdefined_end = False\n",
    "\t\t\tend_title = word_bound_r\n",
    "\t\t\twhile not defined_end:\n",
    "\t\t\t\tword_bound_l = word_bound_r\n",
    "\t\t\t\tword_bound_r = next_from(word_bound_l, file)\n",
    "\n",
    "\t\t\t\tif word_bound_l == len(file):\n",
    "\t\t\t\t\tdefined_end = True\n",
    "\t\t\t\telif not check_caps(file[word_bound_l+1:word_bound_r]) and count_letters(file[word_bound_l+1:word_bound_r]) < 2:\n",
    "\t\t\t\t\tif re.match(r\"[A-ZА-Яa-zа-я]\", file[word_bound_l+1]) != None:\n",
    "\t\t\t\t\t\t# Most possibly belongs to title\n",
    "\t\t\t\t\t\tend_title = word_bound_r\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t# Most possibly NOT belongs to title\n",
    "\t\t\t\t\t\tpass\n",
    "\t\t\t\telif check_caps(file[word_bound_l+1:word_bound_r]):\n",
    "\t\t\t\t\tend_title = word_bound_r\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdefined_end = True\n",
    "\n",
    "\t\t\tnext_title = False\n",
    "\t\t\twhile not next_title:\n",
    "\t\t\t\t# Update root in case it's been changed\n",
    "\t\t\t\troot = parse_xml()\n",
    "\t\t\t\tnum = len(root) + 1\n",
    "\n",
    "\t\t\t\t# Console output for further user actions\n",
    "\t\t\t\tsegment_start = start_title\n",
    "\t\t\t\tsegment_end = end_title\n",
    "\t\t\t\tfor i in range(LEAD_WORDS):\n",
    "\t\t\t\t\tsegment_start = prev_from(segment_start, file)\n",
    "\t\t\t\tfor i in range(AFT_WORDS):\n",
    "\t\t\t\t\tsegment_end = next_from(segment_end, file)\n",
    "\t\t\t\t\n",
    "\t\t\t\tout_str = file[segment_start+1:segment_end]\n",
    "\n",
    "\t\t\t\t# Format\n",
    "\t\t\t\tfor i in range(len(out_str)):\n",
    "\t\t\t\t\tout_str = out_str[:i] + ('$' if out_str[i] == '\\n' else out_str[i]) + out_str[i+1:]\n",
    "\t\t\t\tout_str = f\"{num})\\n\" + out_str + '\\n' + ' ' * (start_title - segment_start) + '^' * (end_title - start_title - 1)\n",
    "\t\t\t\t# Check for \"section\" in the string. This is referred to alphabetic tip at the bottom of the page\n",
    "\t\t\t\t\"\"\"if 'section' in out_str or 'title' in out_str:\n",
    "\t\t\t\t\tout_str += '     ############################### Title or section found! ###############################'\"\"\" # Not Used\n",
    "\t\t\t\tprint(out_str)\n",
    "\n",
    "\t\t\t\t# User actions\n",
    "\t\t\t\tresponse = input()\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tif response == '':\n",
    "\t\t\t\t\t\t# Add article\n",
    "\t\t\t\t\t\tarticle = Article()\n",
    "\t\t\t\t\t\tarticle.start_title = start_title\n",
    "\t\t\t\t\t\tarticle.end_title = end_title\n",
    "\t\t\t\t\t\tarticle.filename = filename\n",
    "\t\t\t\t\t\tadd_artice(article, root, num)\n",
    "\t\t\t\t\t\tnext_title = True\n",
    "\t\t\t\t\t\tword_bound_l = end_title\n",
    "\t\t\t\t\t\tword_bound_r = next_from(word_bound_l, file, end_replace=False)\n",
    "\t\t\t\t\t\tprint(f'Adding article, n=\"{num}\", title=\"{file[start_title+1:end_title]}\"\\n\\n')\n",
    "\t\t\t\t\telif response == 'n' or response == 'т':\n",
    "\t\t\t\t\t\t# Do not add this one\n",
    "\t\t\t\t\t\tnext_title = True\n",
    "\t\t\t\t\t\tprint(\"Not an article, skipping\\n\\n\")\n",
    "\t\t\t\t\telif response[0] == '.':\n",
    "\t\t\t\t\t\tend_title += int(response[1:])\n",
    "\t\t\t\t\t\tprint(\"Changing title right border\\n\\n\")\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t# Change title borders\n",
    "\t\t\t\t\t\tcorrections = response.split(' ')\n",
    "\t\t\t\t\t\tcorrections[0] = int(corrections[0])\n",
    "\t\t\t\t\t\tcorrections[1] = int(corrections[1])\n",
    "\t\t\t\t\t\tif corrections[0] > 0:\n",
    "\t\t\t\t\t\t\tfor i in range(abs(corrections[0])):\n",
    "\t\t\t\t\t\t\t\tstart_title = prev_from(start_title, file)\n",
    "\t\t\t\t\t\tif corrections[0] < 0:\n",
    "\t\t\t\t\t\t\tfor i in range(abs(corrections[0])):\n",
    "\t\t\t\t\t\t\t\tstart_title = next_from(start_title, file)\n",
    "\t\t\t\t\t\tif corrections[1] < 0:\n",
    "\t\t\t\t\t\t\tfor i in range(abs(corrections[1])):\n",
    "\t\t\t\t\t\t\t\tend_title = prev_from(end_title, file)\n",
    "\t\t\t\t\t\tif corrections[1] > 0:\n",
    "\t\t\t\t\t\t\tfor i in range(abs(corrections[1])):\n",
    "\t\t\t\t\t\t\t\tend_title = next_from(end_title, file)\n",
    "\t\t\t\t\t\tprint(\"Changing title borders\\n\\n\")\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tprint(\"########## !!! Failed on input, try again !!! ##########\\n\\n\")\n",
    "\n",
    "\n",
    "# End reached\n",
    "print('###########################################################################################')\n",
    "print('Last requested page processd. Press \"Enter\" to close this window.')\n",
    "response = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Добавление заголовков по одному\n",
    "\n",
    "В разделе параметров указать номер страницы и ТОЧНУЮ формулировку заголовка из сырого текста, после чего запустить ячейку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import codecs\n",
    "\n",
    "\n",
    "############################ VARS ################################\n",
    "PAGES_DIR = \"./matphys/rpages/\"\n",
    "EXIT_DIR = \"./matphys/\"\n",
    "EXIT_FILE = \"FMEv2.xml\"\n",
    "# First and last pages to be parsed\n",
    "PAGE = 224\n",
    "TITLE = 'ИНФИНИТЕЗИМАЛЬНАЯ СВЯЗНОСТЬ'\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\n",
    "class Article:\n",
    "\tstart_title = 0\n",
    "\tend_title = 0\n",
    "\tfilename = ''\n",
    "\n",
    "\n",
    "\n",
    "# Write xml tree to file\n",
    "def prettify(elem):\n",
    "\t# Pretty-printed XML string for the Element.\n",
    "\trough_string = ET.tostring(elem, 'utf-8')\n",
    "\treparsed = minidom.parseString(rough_string)\n",
    "\treturn reparsed.toprettyxml(indent=\"  \")\n",
    "def xml_write(root):\n",
    "\twith codecs.open(EXIT_DIR + EXIT_FILE, 'w', 'utf-8') as f:\n",
    "\t\tf.write(prettify(root))\n",
    "\n",
    "\n",
    "# Get filenames needed\n",
    "filenames_raw = next(walk(PAGES_DIR), (None, None, []))[2]  # [] if no file\n",
    "filenames = []\n",
    "for i in range(PAGE, PAGE + 1):\n",
    "\tfor filename in filenames_raw:\n",
    "\t\tbeginning = \"rp-\" + str(i) + \"_\"\n",
    "\t\tif filename[:len(beginning)] == beginning and filename[-4:] == \".mmd\":\n",
    "\t\t\tfilenames.append(filename)\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "# Check for existing xml\n",
    "filenames_raw = next(walk(EXIT_DIR), (None, None, []))[2]  # [] if no file\n",
    "if not(EXIT_FILE in filenames_raw):\n",
    "\troot = ET.Element('data')\n",
    "\txml_write(root)\n",
    "\n",
    "\n",
    "def remove_xml_spaces(elem):\n",
    "\telem.tail = None\n",
    "\tif elem.text != None:\n",
    "\t\tis_space = True\n",
    "\t\tfor letter in elem.text:\n",
    "\t\t\tis_space = False if letter != ' ' else is_space\n",
    "\t\telem.text = None if is_space else elem.text\n",
    "\tfor subelem in elem:\n",
    "\t\tsubelem = remove_xml_spaces(subelem)\n",
    "\treturn elem\n",
    "\n",
    "# Parse existing xml (string parsing is needed to avoid extra newlines appearing)\n",
    "exit_string = ''\n",
    "with codecs.open(EXIT_DIR + EXIT_FILE, 'r', 'utf-8') as f:\n",
    "\tfor i in f.readlines():\n",
    "\t\texit_string += i[:-1]\n",
    "root = ET.fromstring(exit_string)\n",
    "# Remove empty tails and texts\n",
    "root = remove_xml_spaces(root)\n",
    "\n",
    "\n",
    "# Add article title and metadata to xml tree\n",
    "def add_artice(elem, root, num):\n",
    "\tarticle = ET.SubElement(root, 'article', {'n':str(num)})\n",
    "\ttitle = ET.SubElement(article, 'title')\n",
    "\ttitle.text = file[elem.start_title+1:elem.end_title]\n",
    "\ttitle_meta = ET.SubElement(article, 'title-meta')\n",
    "\ttitle_file = ET.SubElement(title_meta, 'title-file')\n",
    "\ttitle_file.text = elem.filename\n",
    "\ttitle_start = ET.SubElement(title_meta, 'title-start')\n",
    "\ttitle_start.text = str(elem.start_title + 1)\n",
    "\ttitle_end = ET.SubElement(title_meta, 'title-end')\n",
    "\ttitle_end.text = str(elem.end_title)\n",
    "\txml_write(root)\n",
    "\n",
    "# Read requested file\n",
    "with codecs.open(PAGES_DIR + filenames[0], 'r', 'utf-8') as f:\n",
    "\tfile = f.read()\n",
    "\n",
    "# Find titles and add them\n",
    "start_title = 0\n",
    "end_title = 0\n",
    "num = len(root) + 1\n",
    "while file.find(TITLE, end_title) != -1:\n",
    "\tstart_title = file.find(TITLE, start_title)\n",
    "\tend_title = start_title + len(TITLE)\n",
    "\tstart_title -= 1 # Set on space befor the title\n",
    "\n",
    "\tarticle = Article()\n",
    "\tarticle.start_title = max(start_title, 0)\n",
    "\tarticle.end_title = min(end_title, len(file))\n",
    "\tarticle.filename = filenames[0]\n",
    "\tadd_artice(article, root, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Исправление ошибок в заголовках\n",
    "\n",
    "Состоит из двух частей: \"составитель пар\" и \"подстановщик\".\n",
    "\n",
    "Сначала \"составитель\" формирует xml-список всех заголовков с возможными автоматическими исправлениями (в формате было / стало):\n",
    "1. замена латиницы на агалогичную кириллицу;\n",
    "2. замена задаванных буквосочетаний (см. параметры)\n",
    "3. удаление обрамляющих знаков препинания;\n",
    "4. замена всех букв на заглавные (в том числе это избавляет дальнейшей необходимости исправлять имена);\n",
    "5. слияние разорванных на отдельные буквы слов (если рядом оказываются несколько таких слов, то они оказываются слиты вместе).\n",
    "\n",
    "Этот список необходимо просмотреть и исправить оставшиеся ошибки.\n",
    "\n",
    "Затем запустить \"подстановщик\", который заменит все заголовки на исправленные.\n",
    "\n",
    "## 2.1. Составитель пар \"оригинальный - исправленный\" для заголовков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "\n",
    "############################ VARS ################################\n",
    "WORK_DIR = \"./matphys/\"\n",
    "INPUT_FILE = \"FMEv2.xml\"\n",
    "CORRECTION_FILE = \"FMEcorr.xml\"\n",
    "COMBINATIONS_CORR = {\n",
    "\t'U' : 'И',\n",
    "\t'r' : 'г',\n",
    "\t'n' : 'п',\n",
    "\t'Y' : 'У',\n",
    "\t' -' : '-',\n",
    "\t'- ' : '-',\n",
    "\t'S' : 'Я',\n",
    "\t'ХК' : 'Ж',\n",
    "\t'0' : 'О',\n",
    "\t'3' : 'З',\n",
    "\t'6' : 'б'\n",
    "}\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Write xml tree to file\n",
    "def prettify(elem):\n",
    "\t# Pretty-printed XML string for the Element.\n",
    "\trough_string = ET.tostring(elem, 'utf-8')\n",
    "\treparsed = minidom.parseString(rough_string)\n",
    "\treturn reparsed.toprettyxml(indent=\"  \")\n",
    "def xml_write(root):\n",
    "\twith codecs.open(WORK_DIR + CORRECTION_FILE, 'w', 'utf-8') as f:\n",
    "\t\tf.write(prettify(root))\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "# Check for existing xml\n",
    "filenames_raw = next(walk(WORK_DIR), (None, None, []))[2]  # [] if no file\n",
    "if not(INPUT_FILE in filenames_raw):\n",
    "\troot = ET.Element('data')\n",
    "\txml_write(root)\n",
    "\n",
    "\n",
    "# Parse input xml\n",
    "exit_string = ''\n",
    "with codecs.open(WORK_DIR + INPUT_FILE, 'r', 'utf-8') as f:\n",
    "\tfor i in f.readlines():\n",
    "\t\texit_string += i[:-1]\n",
    "root = ET.fromstring(exit_string)\n",
    "\n",
    "\n",
    "# Get all the titles into a dict\n",
    "titles_dict = {}\n",
    "pages_dict = {}\n",
    "for article in root:\n",
    "\tfor elem in article:\n",
    "\t\tif elem.tag == 'title':\n",
    "\t\t\ttitles_dict[elem.text] = elem.text\n",
    "\t\t\ttitle = elem.text\n",
    "\t\tif elem.tag == 'title-meta':\n",
    "\t\t\tfor eelem in elem:\n",
    "\t\t\t\tif eelem.tag == 'title-file':\n",
    "\t\t\t\t\tpages_dict[title] = eelem.text[eelem.text.find('-')+1:eelem.text.find('_')]\n",
    "\n",
    "\n",
    "# Correct latin letters\n",
    "letter_corr = {'A':'А', 'a':'а', 'B':'В', 'b':'Ь', 'E':'Е', 'e':'е', 'H':'Н', 'K':'К', 'M':'М', 'O':'О', 'P':'Р', 'p':'р', 'T':'Т', 'X':'Х', 'x':'x', 'y':'у'}\n",
    "for title in titles_dict.keys():\n",
    "\ttitle_new = titles_dict[title]\n",
    "\tfor i in range(len(title_new)):\n",
    "\t\tif title_new[i] in letter_corr:\n",
    "\t\t\ttitle_new = title_new[:i] + letter_corr[title_new[i]] + title_new[i+1:]\n",
    "\ttitles_dict[title] = title_new\n",
    "\n",
    "# Correct preferred combinations\n",
    "for title in titles_dict.keys():\n",
    "\ttitle_new = titles_dict[title]\n",
    "\tfor comb in COMBINATIONS_CORR.keys():\n",
    "\t\twhile title_new.find(comb) != -1:\n",
    "\t\t\ttitle_new = title_new[:title_new.find(comb)] + COMBINATIONS_CORR[comb] + title_new[title_new.find(comb) + len(comb):]\n",
    "\ttitles_dict[title] = title_new\n",
    "\n",
    "# Remove bounding symbols\n",
    "for title in titles_dict.keys():\n",
    "\ttitle_new = titles_dict[title]\n",
    "\twhile re.match(r\"[!#%&'*+-.^_`|~:;]\", title_new[0]) != None:\n",
    "\t\ttitle_new = title_new[1:]\n",
    "\twhile re.match(r\"[!#%&'*+-.^_`|~:;]\", title_new[-1]) != None:\n",
    "\t\ttitle_new = title_new[:-1]\n",
    "\ttitles_dict[title] = title_new\n",
    "\n",
    "# CAPS\n",
    "for title in titles_dict.keys():\n",
    "\ttitles_dict[title] = titles_dict[title].upper()\n",
    "\n",
    "# Merge single-lettered words\n",
    "for title in titles_dict.keys():\n",
    "\ttitle_new = titles_dict[title]\n",
    "\ttitle_new = ' ' + title_new + ' '\n",
    "\tfor i in range(len(title_new) - 4):\n",
    "\t\tif (title_new[i] == ' ' or title_new[i] == '№') and title_new[i + 2] == ' ' and title_new[i + 4] == ' ':\n",
    "\t\t\ttitle_new = title_new[:i+2] + '№' + title_new[i+3:]\n",
    "\ti = 0\n",
    "\twhile i < len(title_new):\n",
    "\t\tif title_new[i] == '№':\n",
    "\t\t\ttitle_new = title_new[:i] + title_new[i+1:]\n",
    "\t\t\ti = 0\n",
    "\t\telse:\n",
    "\t\t\ti += 1\n",
    "\twhile title_new[0] == ' ':\n",
    "\t\ttitle_new = title_new[1:]\n",
    "\twhile title_new[-1] == ' ':\n",
    "\t\ttitle_new = title_new[:-1]\n",
    "\ttitles_dict[title] = title_new\n",
    "\n",
    "\n",
    "# Write corrections xml\n",
    "root = ET.Element('data')\n",
    "for i in titles_dict.items():\n",
    "\tpair = ET.SubElement(root, 'pair')\n",
    "\ttitle_old = ET.SubElement(pair, 'title_old')\n",
    "\ttitle_old.text = i[0]\n",
    "\ttitle_new = ET.SubElement(pair, 'title_new')\n",
    "\ttitle_new.text = i[1]\n",
    "\tpage = ET.SubElement(pair, 'page')\n",
    "\tpage.text = pages_dict[i[0]]\n",
    "xml_write(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Подстановщик исправленных заголовков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import codecs\n",
    "\n",
    "\n",
    "############################ VARS ################################\n",
    "WORK_DIR = \"./matphys/\"\n",
    "INPUT_FILE = \"FMEv2.xml\"\n",
    "CORRECTION_FILE = \"FMEcorr.xml\"\n",
    "EXIT_FILE = \"FMEtitles.xml\"\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Write xml tree to file\n",
    "def prettify(elem):\n",
    "\t# Pretty-printed XML string for the Element.\n",
    "\trough_string = ET.tostring(elem, 'utf-8')\n",
    "\treparsed = minidom.parseString(rough_string)\n",
    "\treturn reparsed.toprettyxml(indent=\"  \")\n",
    "def xml_write(root):\n",
    "\twith codecs.open(WORK_DIR + EXIT_FILE, 'w', 'utf-8') as f:\n",
    "\t\tf.write(prettify(root))\n",
    "\n",
    "\n",
    "# Parse input xml\n",
    "exit_string = ''\n",
    "with codecs.open(WORK_DIR + CORRECTION_FILE, 'r', 'utf-8') as f:\n",
    "\tfor i in f.readlines():\n",
    "\t\texit_string += i[:-1]\n",
    "root = ET.fromstring(exit_string)\n",
    "\n",
    "\n",
    "# Get all the corrections into a dict\n",
    "titles_dict = {}\n",
    "for pair in root:\n",
    "\tfor elem in pair:\n",
    "\t\tif elem.tag == 'title_old':\n",
    "\t\t\ttitle_old = elem.text\n",
    "\t\tif elem.tag == 'title_new':\n",
    "\t\t\ttitle_new = elem.text\n",
    "\ttitles_dict[title_old] = title_new\n",
    "\n",
    "\n",
    "def remove_xml_spaces(elem):\n",
    "\telem.tail = None\n",
    "\tif elem.text != None:\n",
    "\t\tis_space = True\n",
    "\t\tfor letter in elem.text:\n",
    "\t\t\tis_space = False if letter != ' ' else is_space\n",
    "\t\telem.text = None if is_space else elem.text\n",
    "\tfor subelem in elem:\n",
    "\t\tsubelem = remove_xml_spaces(subelem)\n",
    "\treturn elem\n",
    "# Parse existing exit xml (string parsing is needed to avoid extra newlines appearing)\n",
    "exit_string = ''\n",
    "with codecs.open(WORK_DIR + INPUT_FILE, 'r', 'utf-8') as f:\n",
    "\tfor i in f.readlines():\n",
    "\t\texit_string += i[:-1]\n",
    "root = ET.fromstring(exit_string)\n",
    "# Remove empty tails and texts\n",
    "root = remove_xml_spaces(root)\n",
    "\n",
    "\n",
    "# Replace titles\n",
    "for article in root:\n",
    "\tfor elem in article:\n",
    "\t\tif elem.tag == 'title':\n",
    "\t\t\telem.text = titles_dict[elem.text]\n",
    "xml_write(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Сортировщик / сливщик файлов с заголовками\n",
    "\n",
    "Сортирует статьи в файлах из данного списка в порядке страница-расположение, т.е. (если не сказано иного) в алфавитном порядке и выводит в один выходной файл. Также порядковый номер заменяется uri формата \"http://libmeta.ru/fme/article/1_Kraevaya\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import codecs\n",
    "from transliterate import translit, get_available_language_codes\n",
    "\n",
    "\n",
    "############################ VARS ################################\n",
    "WORK_DIR = \"./results/\"\n",
    "INPUT_FILES = [\"FMEtitles-p5-100.xml\", \"FMEtitles-p101-200.xml\", \"FMEtitles-p201-300.xml\"]\n",
    "EXIT_FILE = \"FMEtitles-merged.xml\"\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\n",
    "class Article:\n",
    "\ttitle = ''\n",
    "\tstart_title = ''\n",
    "\tend_title = ''\n",
    "\tfilename = ''\n",
    "\n",
    "\n",
    "\n",
    "# Write xml tree to file\n",
    "def prettify(elem):\n",
    "\t# Pretty-printed XML string for the Element.\n",
    "\trough_string = ET.tostring(elem, 'utf-8')\n",
    "\treparsed = minidom.parseString(rough_string)\n",
    "\treturn reparsed.toprettyxml(indent=\"  \")\n",
    "def xml_write(root):\n",
    "\twith codecs.open(WORK_DIR + EXIT_FILE, 'w', 'utf-8') as f:\n",
    "\t\tf.write(prettify(root))\n",
    "\n",
    "\n",
    "# Add article title and metadata to xml tree\n",
    "def add_artice(elem, root, num):\n",
    "\tarticle = ET.SubElement(root, 'article', {'uri':\"http://libmeta.ru/fme/article/\"+str(num)+\"_\"+translit(elem.title[:elem.title.find(' ')], 'ru', True)})\n",
    "\ttitle = ET.SubElement(article, 'title')\n",
    "\ttitle.text = elem.title\n",
    "\ttitle_meta = ET.SubElement(article, 'title-meta')\n",
    "\ttitle_file = ET.SubElement(title_meta, 'title-file')\n",
    "\ttitle_file.text = elem.filename\n",
    "\ttitle_start = ET.SubElement(title_meta, 'title-start')\n",
    "\ttitle_start.text = str(int(elem.start_title) + 1)\n",
    "\ttitle_end = ET.SubElement(title_meta, 'title-end')\n",
    "\ttitle_end.text = elem.end_title\n",
    "\n",
    "\n",
    "def remove_xml_spaces(elem):\n",
    "\telem.tail = None\n",
    "\tif elem.text != None:\n",
    "\t\tis_space = True\n",
    "\t\tfor letter in elem.text:\n",
    "\t\t\tis_space = False if letter != ' ' else is_space\n",
    "\t\telem.text = None if is_space else elem.text\n",
    "\tfor subelem in elem:\n",
    "\t\tsubelem = remove_xml_spaces(subelem)\n",
    "\treturn elem\n",
    "def parse_xml(filename):\n",
    "\t# Parse existing xml (string parsing is needed to avoid extra newlines appearing)\n",
    "\texit_string = ''\n",
    "\twith codecs.open(WORK_DIR + filename, 'r', 'utf-8') as f:\n",
    "\t\tfor i in f.readlines():\n",
    "\t\t\texit_string += i[:-1]\n",
    "\troot = ET.fromstring(exit_string)\n",
    "\troot = remove_xml_spaces(root)\n",
    "\treturn root\n",
    "\n",
    "\n",
    "# Collect all the articles\n",
    "articles_dict = {}\n",
    "for filename in INPUT_FILES:\n",
    "\troot = parse_xml(filename)\n",
    "\tfor article in root:\n",
    "\t\tnum = ()\n",
    "\t\tpage = ''\n",
    "\t\tpos = ''\n",
    "\t\ttitle = ''\n",
    "\t\tstart = ''\n",
    "\t\tend = ''\n",
    "\t\tfile = ''\n",
    "\t\tfor tag in article:\n",
    "\t\t\ttitle += tag.text if tag.tag == 'title' else ''\n",
    "\t\t\tif tag.tag == 'title-meta':\n",
    "\t\t\t\tfor taag in tag:\n",
    "\t\t\t\t\tpage += taag.text[taag.text.find('-')+1:taag.text.find('_')] if taag.tag == 'title-file' else ''\n",
    "\t\t\t\tfor taag in tag:\n",
    "\t\t\t\t\tpos += taag.text if taag.tag == 'title-start' else ''\n",
    "\t\t\t\t\tstart += taag.text if taag.tag == 'title-start' else ''\n",
    "\t\t\t\t\tend += taag.text if taag.tag == 'title-end' else ''\n",
    "\t\t\t\t\tfile += taag.text if taag.tag == 'title-file' else ''\n",
    "\t\t\t\tnum = (int(page), int(pos))\n",
    "\t\tarticles_dict[num] = {'title':title, 'file':file, 'start':start, 'end':end}\n",
    "\n",
    "\n",
    "# Sort keys and wrtite articles accordingly\n",
    "root = ET.Element('data')\n",
    "nums_list = sorted(list(i for i in articles_dict.keys()))\n",
    "for num in range(len(nums_list)):\n",
    "\tarticle = Article()\n",
    "\tarticle.title = articles_dict[nums_list[num]]['title']\n",
    "\tarticle.start_title = articles_dict[nums_list[num]]['start']\n",
    "\tarticle.end_title = articles_dict[nums_list[num]]['end']\n",
    "\tarticle.filename = articles_dict[nums_list[num]]['file']\n",
    "\tadd_artice(article, root, num + 1)\n",
    "xml_write(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Парсер текстов статей\n",
    "\n",
    "По информации из указанного файла с заголовками вытаскивает в сыром виде тексты статей. Каждая статья помещается в свой .tex файл, с заголовком, содержащим номер статьи и первое слово из заголовка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import codecs\n",
    "\n",
    "\n",
    "############################ VARS ################################\n",
    "TITLES_FILE = \"./results/FMEtitles-merged.xml\"\n",
    "PAGES_DIR = \"./matphys/rpages/\"\n",
    "EXIT_DIR = \"./results/FMEarticles/\"\n",
    "##################################################################\n",
    "\n",
    "\n",
    "class Article:\n",
    "\tstart_file = ''\n",
    "\tstart_pos = 0\n",
    "\tend_file = ''\n",
    "\tend_pos = 0\n",
    "\ttext = ''\n",
    "\turi = ''\n",
    "\ttitle = ''\n",
    "\txml = ''\n",
    "\n",
    "\tdef get_text(self):\n",
    "\t\tif self.start_file == self.end_file:\n",
    "\t\t\twith codecs.open(PAGES_DIR + self.start_file, 'r', 'utf-8') as f:\n",
    "\t\t\t\tself.text += f.read()[self.start_pos:self.end_pos]\n",
    "\t\telse:\n",
    "\t\t\twith codecs.open(PAGES_DIR + self.start_file, 'r', 'utf-8') as f:\n",
    "\t\t\t\tself.text += f.read()[self.start_pos:]\n",
    "\t\t\tself.text += ' ' # Add a space to prevent word merging\n",
    "\t\t\twith codecs.open(PAGES_DIR + self.end_file, 'r', 'utf-8') as f:\n",
    "\t\t\t\tself.text += f.read()[:self.end_pos]\n",
    "\t\t\t\t\n",
    "\tdef prettify(elem):\n",
    "\t\t# Pretty-printed XML string for the Element.\n",
    "\t\trough_string = ET.tostring(elem, 'utf-8')\n",
    "\t\treparsed = minidom.parseString(rough_string)\n",
    "\t\treturn reparsed.toprettyxml(indent=\"  \")\n",
    "\t\n",
    "\tdef make_xml(self):\n",
    "\t\tself.get_text()\n",
    "\n",
    "\t\tarticle = ET.Element(\"article\", {'uri':self.uri})\n",
    "\t\ttitle = ET.SubElement(article, 'title')\n",
    "\t\ttitle.text = self.title\n",
    "\t\tauthor = ET.SubElement(article, 'author')\n",
    "\t\ttitle_short = ET.SubElement(article, 'title_short')\n",
    "\t\tpages = ET.SubElement(article, 'pages')\n",
    "\t\tstart = ET.SubElement(pages, 'start')\n",
    "\t\tstart.text = self.start_file[3:self.start_file.find('_', 3)]\n",
    "\t\tend = ET.SubElement(pages, 'end')\n",
    "\t\tend.text = self.end_file[3:self.end_file.find('_', 3)]\n",
    "\t\tliterature = ET.SubElement(article, 'literature')\n",
    "\t\tliterature_orig = ET.SubElement(literature, 'literature_orig')\n",
    "\t\tformulas_remote = ET.SubElement(article, 'formulas_main')\n",
    "\t\tformulas_inline = ET.SubElement(article, 'formulas_aux')\n",
    "\t\trelations = ET.SubElement(article, 'relations')\n",
    "\t\ttext = ET.SubElement(article, 'text')\n",
    "\t\ttext.text = self.text\n",
    "\t\ttext_orig = ET.SubElement(article, 'text_orig')\n",
    "\t\ttext_orig.text = self.text\n",
    "\n",
    "\t\tself.xml = prettify(article)\n",
    "\t\n",
    "\t\n",
    "\n",
    "class Title:\n",
    "\ttext = ''\n",
    "\tfile = ''\n",
    "\tstart_pos = 0\n",
    "\tend_pos = 0\n",
    "\turi = ''\n",
    "\n",
    "\n",
    "def remove_xml_spaces(elem):\n",
    "\telem.tail = None\n",
    "\tif elem.text != None:\n",
    "\t\tis_space = True\n",
    "\t\tfor letter in elem.text:\n",
    "\t\t\tis_space = False if letter != ' ' else is_space\n",
    "\t\telem.text = None if is_space else elem.text\n",
    "\tfor subelem in elem:\n",
    "\t\tsubelem = remove_xml_spaces(subelem)\n",
    "\treturn elem\n",
    "\n",
    "def parse_xml(filename):\n",
    "\t# Parse existing xml (string parsing is needed to avoid extra newlines appearing)\n",
    "\texit_string = ''\n",
    "\twith codecs.open(filename, 'r', 'utf-8') as f:\n",
    "\t\tfor i in f.readlines():\n",
    "\t\t\texit_string += i[:-1]\n",
    "\troot = ET.fromstring(exit_string)\n",
    "\t# Remove empty tails and texts\n",
    "\troot = remove_xml_spaces(root)\n",
    "\treturn root\n",
    "\n",
    "def get_title(n, root):\n",
    "\totitle = Title()\n",
    "\tfor title in root:\n",
    "\t\tif int(title.attrib['uri'][30:title.attrib['uri'].find('_', 30)]) == n:\n",
    "\t\t\totitle.uri = title.attrib['uri']\n",
    "\t\t\tfor tag in title:\n",
    "\t\t\t\tif tag.tag == 'title':\n",
    "\t\t\t\t\totitle.text = tag.text\n",
    "\t\t\t\tif tag.tag == 'title-meta':\n",
    "\t\t\t\t\tfor ttag in tag:\n",
    "\t\t\t\t\t\tif ttag.tag == 'title-file':\n",
    "\t\t\t\t\t\t\totitle.file = ttag.text\n",
    "\t\t\t\t\t\telif ttag.tag == 'title-start':\n",
    "\t\t\t\t\t\t\totitle.start_pos = int(ttag.text)\n",
    "\t\t\t\t\t\telif ttag.tag == 'title-end':\n",
    "\t\t\t\t\t\t\totitle.end_pos = int(ttag.text)\n",
    "\treturn otitle\n",
    "\n",
    "\n",
    "root = parse_xml(TITLES_FILE)\n",
    "\n",
    "# Create articles list\n",
    "articles_list = []\n",
    "title = Title()\n",
    "for i in range(len(root)):\n",
    "\ttitle = get_title(i + 1, root)\n",
    "\tif i:\n",
    "\t\tarticles_list[-1].end_file = title.file\n",
    "\t\tarticles_list[-1].end_pos = title.start_pos - 2 # There is a shift for some reason\n",
    "\tarticles_list.append(Article())\n",
    "\tarticles_list[-1].uri = title.uri\n",
    "\tarticles_list[-1].title = title.text\n",
    "\tarticles_list[-1].start_file = title.file\n",
    "\tarticles_list[-1].start_pos = title.end_pos\n",
    "\tarticles_list[-1].end_file = title.file\n",
    "\twith codecs.open(PAGES_DIR + title.file, 'r', 'utf-8') as f:\n",
    "\t\tarticles_list[-1].end_pos = len(f.read())\n",
    "\n",
    "# Parse texts themselves and write\n",
    "for i in range(len(articles_list)):\n",
    "\tarticles_list[i].make_xml()\n",
    "\twith codecs.open(EXIT_DIR + '' + articles_list[i].uri[30:] + '.xml', 'w', 'utf-8') as f:\n",
    "\t\tf.write(articles_list[i].xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Парсер формул\n",
    "\n",
    "Выносит из текстов ранее подготовленных xml-файлов статей сначала выносные, а затем строчные формулы, оставляя на их месте ссылку внутри их математического окружения. \n",
    "\n",
    "Минимальная длина в символах, которой должна обладать строчная формула, настраивается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import codecs\n",
    "\n",
    "\n",
    "############################ VARS ################################\n",
    "ARTICLES_DIR = \"./results/FMEarticles/\"\n",
    "MIN_INLINE_LEN = 0\n",
    "##################################################################\n",
    "\n",
    "\n",
    "# Write xml tree to file\n",
    "def prettify(elem):\n",
    "\t# Pretty-printed XML string for the Element.\n",
    "\trough_string = ET.tostring(elem, 'utf-8')\n",
    "\treparsed = minidom.parseString(rough_string)\n",
    "\treturn reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "\n",
    "def remove_xml_spaces(elem):\n",
    "\telem.tail = None\n",
    "\tif elem.text != None:\n",
    "\t\tis_space = True\n",
    "\t\tfor letter in elem.text:\n",
    "\t\t\tis_space = False if letter != ' ' else is_space\n",
    "\t\telem.text = None if is_space else elem.text\n",
    "\tfor subelem in elem:\n",
    "\t\tsubelem = remove_xml_spaces(subelem)\n",
    "\treturn elem\n",
    "\n",
    "def parse_xml(filename):\n",
    "\t# Parse existing xml (string parsing is needed to avoid extra newlines appearing)\n",
    "\texit_string = ''\n",
    "\twith codecs.open(filename, 'r', 'utf-8') as f:\n",
    "\t\tfor i in f.readlines():\n",
    "\t\t\texit_string += i[:-1]\n",
    "\troot = ET.fromstring(exit_string)\n",
    "\t# Remove empty tails and texts\n",
    "\troot = remove_xml_spaces(root)\n",
    "\treturn root\n",
    "\n",
    "\n",
    "# Get filenames needed\n",
    "filenames = next(walk(ARTICLES_DIR), (None, None, []))[2]  # [] if no file\n",
    "\n",
    "for filename in filenames:\n",
    "\t# !!!BUG!!! for some reason newlines diappear in texts in parsed xml, so extract article texts manually and replace\n",
    "\twith codecs.open(ARTICLES_DIR + filename, 'r', 'utf-8') as f:\n",
    "\t\tfile = f.read()\n",
    "\tarticle = parse_xml(ARTICLES_DIR + filename)\n",
    "\t#print('REMOTES: ' + article.attrib['uri'])\n",
    "\tfor subelem in article:\n",
    "\t\tif subelem.tag == 'text':\n",
    "\t\t\tsubelem.text = file[file.find('<text>')+6:file.find('</text>')]\n",
    "\t\t\ttext = subelem\n",
    "\t\tif subelem.tag == 'text_orig':\n",
    "\t\t\tsubelem.text = file[file.find('<text_orig>')+11:file.find('</text_orig>')]\n",
    "\t\tif subelem.tag == 'formulas_main':\n",
    "\t\t\tformulas_main = subelem\n",
    "\t\tif subelem.tag == 'formulas_aux':\n",
    "\t\t\tformulas_aux = subelem\n",
    "\t\t\t\n",
    "# Get main formulas\n",
    "\tpos_find = 0\n",
    "\tpos_start = 0\n",
    "\tpos_end = 0\n",
    "\tn = 1\n",
    "\twhile text.text != None and text.text.find('\\\\[', pos_find) != -1:\n",
    "\t\tpos_start = text.text.find('\\\\[', pos_find) + 2\n",
    "\t\tpos_end = text.text.find('\\\\]', pos_start)\n",
    "\t\twhile text.text[pos_start] == '\\n':\n",
    "\t\t\tpos_start += 1\n",
    "\t\twhile text.text[pos_end-1] == '\\n':\n",
    "\t\t\tpos_end -= 1\n",
    "\t\tpos_find = pos_start\n",
    "\t\turi = 'http://libmeta.ru/fme/formula/main' + article.attrib['uri'][article.attrib['uri'].rfind('/', 0, article.attrib['uri'].find('_')):article.attrib['uri'].find('_')+1] + str(n) + article.attrib['uri'][article.attrib['uri'].find('_'):]\n",
    "\t\tn += 1\n",
    "\t\tformula = ET.SubElement(formulas_main, 'formula', {'uri':uri})\n",
    "\t\tformula.text = text.text[pos_start:pos_end]\n",
    "\t\ttext.text = text.text[:pos_start] + 'URI[[' + uri + ']]/URI' + text.text[pos_end:]\n",
    "\n",
    "# Get auxilary formulas\n",
    "\tpos_find = 0\n",
    "\tpos_start = 0\n",
    "\tpos_end = 0\n",
    "\tcnt = 0\n",
    "\tn = 1\n",
    "\t# Count dollar symbols\n",
    "\twhile text.text.find('$', pos_find) != -1:\n",
    "\t\tpos_find = text.text.find('$', pos_find) + 1\n",
    "\t\tcnt += 1\n",
    "\t# If cnt is not even assume that first one is garbage from title\n",
    "\tpos_find = 0\n",
    "\tif cnt % 2:\n",
    "\t\tpos_find = text.text.find('$', pos_find)\n",
    "\t\ttext.text = text.text[:pos_find] + '#' + text.text[pos_find+1:]\n",
    "\twhile text.text.find('$', pos_find) != -1:\n",
    "\t\tpos_start = text.text.find('$', pos_find) + 1\n",
    "\t\tpos_end = text.text.find('$', pos_start)\n",
    "\t\twhile text.text[pos_start] == '\\n':\n",
    "\t\t\tpos_start += 1\n",
    "\t\twhile text.text[pos_end-1] == '\\n':\n",
    "\t\t\tpos_end -= 1\n",
    "\t\tpos_find = pos_start\n",
    "\t\tif pos_end - pos_start >= MIN_INLINE_LEN:\n",
    "\t\t\turi = 'http://libmeta.ru/fme/formula/aux' + article.attrib['uri'][article.attrib['uri'].rfind('/', 0, article.attrib['uri'].find('_')):article.attrib['uri'].find('_')+1] + str(n) + article.attrib['uri'][article.attrib['uri'].find('_'):]\n",
    "\t\t\tn += 1\n",
    "\t\t\tformula = ET.SubElement(formulas_aux, 'formula', {'uri':uri})\n",
    "\t\t\tformula.text = text.text[pos_start:pos_end]\n",
    "\t\t\ttext.text = text.text[:pos_start] + 'URI[[' + uri + ']]/URI' + text.text[pos_end:]\n",
    "\t\tpos_find = text.text.find('$', pos_find) + 1\n",
    "\n",
    "\twith codecs.open(ARTICLES_DIR + filename, 'w', 'utf-8') as f:\n",
    "\t\tf.write(prettify(article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1. Вынос формул\n",
    "\n",
    "Выносит все формулы в отдельный файл с указанием типа для возможной последующей обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import codecs\n",
    "\n",
    "\n",
    "############################ VARS ################################\n",
    "ARTICLES_DIR = \"./results/FMEarticles/\"\n",
    "EXIT_FILE = \"./results/FMEformulas.xml\"\n",
    "##################################################################\n",
    "\n",
    "\n",
    "# Write xml tree to file\n",
    "def prettify(elem):\n",
    "\t# Pretty-printed XML string for the Element.\n",
    "\trough_string = ET.tostring(elem, 'utf-8')\n",
    "\treparsed = minidom.parseString(rough_string)\n",
    "\treturn reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "\n",
    "def remove_xml_spaces(elem):\n",
    "\telem.tail = None\n",
    "\tif elem.text != None:\n",
    "\t\tis_space = True\n",
    "\t\tfor letter in elem.text:\n",
    "\t\t\tis_space = False if letter != ' ' else is_space\n",
    "\t\telem.text = None if is_space else elem.text\n",
    "\tfor subelem in elem:\n",
    "\t\tsubelem = remove_xml_spaces(subelem)\n",
    "\treturn elem\n",
    "\n",
    "def parse_xml(filename):\n",
    "\t# Parse existing xml (string parsing is needed to avoid extra newlines appearing)\n",
    "\texit_string = ''\n",
    "\twith codecs.open(filename, 'r', 'utf-8') as f:\n",
    "\t\tfor i in f.readlines():\n",
    "\t\t\texit_string += i[:-1]\n",
    "\troot = ET.fromstring(exit_string)\n",
    "\t# Remove empty tails and texts\n",
    "\troot = remove_xml_spaces(root)\n",
    "\treturn root\n",
    "\n",
    "\n",
    "# Get filenames needed\n",
    "filenames = next(walk(ARTICLES_DIR), (None, None, []))[2]  # [] if no file\n",
    "\n",
    "\n",
    "formulas = ET.Element('formulas')\n",
    "\n",
    "for filename in filenames:\n",
    "\troot = parse_xml(ARTICLES_DIR + filename)\n",
    "\tfor elem in root:\n",
    "\t\tif elem.tag == 'formulas_main':\n",
    "\t\t\tfmain = elem\n",
    "\t\tif elem.tag == 'formulas_aux':\n",
    "\t\t\tfaux = elem\n",
    "\t\n",
    "\tfor formula in fmain:\n",
    "\t\tformulas.append(formula)\n",
    "\t\tformulas[-1].attrib['type'] = 'main'\n",
    "\tfor formula in faux:\n",
    "\t\tformulas.append(formula)\n",
    "\t\tformulas[-1].attrib['type'] = 'aux'\n",
    "\n",
    "with codecs.open(EXIT_FILE, 'w', 'utf-8') as f:\n",
    "\tf.write(prettify(formulas))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Базовый парсер\n",
    "\n",
    "Вытаскивает из latex-кода заголовки статей и их расположение в файлах.\n",
    "\n",
    "Разбивка происходит в полуручном режиме, т.к. нет уверенности в формате заголовков.\n",
    "\n",
    "В тексте ищутся слова, содержащие в своём составе заглавные буквы на русском и английском языках в отношении, большем или равным заданному (по умолчанию 0.66). Предполагается, что таким образом удаётся обнаруживать неправильно машиинно распознанный капс. Слова или цепочки слов, состоящие из одного строчного символа включаются в заголовок, если стоят между слов, определённых как часть заголовка. При этом, одиночные заглавные буквы, а также инициалы не воспринимаются как начало заголовка.\n",
    "\n",
    "## Использование\n",
    "- При удовлетворительном определении заголовка нажать `Enter` без дополнительного ввода.\n",
    "- Если предложенное место заголовком не является ввести `\"n\"`\n",
    "- При неправильном определении границ заголовка ввести два корректировочных числа для сдвига левой и правой границы.\n",
    "  - ЗАМЕЧАНИЕ: сдвиг производится попробельно, т.е. двойной пробел будет распознан как слово нулевой длины.\n",
    "  - ЗАМЕЧАНИЕ: границы отображаемого фрагмента текста будут передвинуты автоматически. Длины левой и правой границ в словах задаются в параметрах.\n",
    "  - ПРИМЕРЫ:\n",
    "    - `out: a [B C] d e f` -> `in: 0 2` -> `out: a [B C D E] f`\n",
    "    - `out: a b c [D E] f` -> `in: 2 -1` -> `out: a [B C D] e f`\n",
    "- Также возможен посимвольный сдвиг правой границы в случае \"сращивания\" заголовка статьи и её текста. Ввести одно число, начиная с точки.\n",
    "  - ПРИМЕРЫ:\n",
    "    - `out: a[BC]def` -> `in: .2` -> `out: a[BCDE]f`\n",
    "    - `out: a[BCDE]f` -> `in: .-1` -> `out: a[BCD]ef`\n",
    "\n",
    "В выводе в терминале переносы строк для удобства заменены на `\"$\"`\n",
    "\n",
    "### Прочее\n",
    "- Для определителя капса достуны исключения, которые никогда не будут рассматриваться, как потенциальные начала заголовков, см. опции. По умолчанию: первые 10 римских цифр и \"МэВ\".\n",
    "- Использовать системный терминал для взаимодействия оказывается удобнее, чем использовать jupyter, поэтому можно скопировать ячейку с кодом в файл `scripter.py` и запускать его.\n",
    "- При положительном определении заголовка файл дополняется немедленно, прервать процесс можно в любой момент, как и продолжить после -- итоговый файл будет дополяться, а не перезаписываться с нуля при новом запуске программы (главное не забыть предварительно удалить из конца файла дубликаты, если вы начинаете с той страницы, на которой закончили в прошлый раз, а не со следующей)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################ rp-104_2023_07_08_c9e658ddccab043daaa4g.mmd ################################\n",
      "17)\n",
      "a_{l}^{-} a_{m}^{-},$\\]$$104 ВТОРИЧНОЕ где$$\\[$\\begin{gathered}$H_{i\n",
      "                             ^^^^^^^^^\n",
      "Changing title borders\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'т'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 228\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mChanging title borders\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m corrections \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 228\u001b[0m corrections[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(corrections[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m    229\u001b[0m corrections[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(corrections[\u001b[39m1\u001b[39m])\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m corrections[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'т'"
     ]
    }
   ],
   "source": [
    "from os import walk\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "\n",
    "############################ VARS ################################\n",
    "PAGES_DIR = \"./matphys/rpages/\"\n",
    "EXIT_DIR = \"./matphys/\"\n",
    "EXIT_FILE = \"FMEv2.xml\"\n",
    "# First and last pages to be parsed\n",
    "START_PAGE = 163\n",
    "END_PAGE = 200\n",
    "# How many words to display before and after a potential title\n",
    "LEAD_WORDS = 5\n",
    "AFT_WORDS = 5\n",
    "# Look in the description\n",
    "CAPS_QUOT = 0.51\n",
    "EXCEPTIONS = ['I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X', 'МэВ']\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\n",
    "class Article:\n",
    "\tstart_title = 0\n",
    "\tend_title = 0\n",
    "\tfilename = ''\n",
    "\n",
    "\n",
    "\n",
    "# Write xml tree to file\n",
    "def prettify(elem):\n",
    "\t# Pretty-printed XML string for the Element.\n",
    "\trough_string = ET.tostring(elem, 'utf-8')\n",
    "\treparsed = minidom.parseString(rough_string)\n",
    "\treturn reparsed.toprettyxml(indent=\"  \")\n",
    "def xml_write(root):\n",
    "\twith codecs.open(EXIT_DIR + EXIT_FILE, 'w', 'utf-8') as f:\n",
    "\t\tf.write(prettify(root))\n",
    "\n",
    "\n",
    "# Get filenames needed\n",
    "filenames_raw = next(walk(PAGES_DIR), (None, None, []))[2]  # [] if no file\n",
    "filenames = []\n",
    "for i in range(START_PAGE, END_PAGE + 1):\n",
    "\tfor filename in filenames_raw:\n",
    "\t\tbeginning = \"rp-\" + str(i) + \"_\"\n",
    "\t\tif filename[:len(beginning)] == beginning and filename[-4:] == \".mmd\":\n",
    "\t\t\tfilenames.append(filename)\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "# Check for existing xml\n",
    "filenames_raw = next(walk(EXIT_DIR), (None, None, []))[2]  # [] if no file\n",
    "if not(EXIT_FILE in filenames_raw):\n",
    "\troot = ET.Element('data')\n",
    "\txml_write(root)\n",
    "\n",
    "\n",
    "# Parse existing xml (string parsing is needed to avoid extra newlines appearing)\n",
    "exit_string = ''\n",
    "with codecs.open(EXIT_DIR + EXIT_FILE, 'r', 'utf-8') as f:\n",
    "\tfor i in f.readlines():\n",
    "\t\texit_string += i[:-1]\n",
    "root = ET.fromstring(exit_string)\n",
    "# Remove empty tails and texts\n",
    "root.tail = None\n",
    "root.text = None\n",
    "for i in root:\n",
    "\ti.tail = None\n",
    "\ti.text = None\n",
    "\tfor j in i:\n",
    "\t\tj.tail = None\n",
    "\t\tis_space = True\n",
    "\t\tfor letter in j.text:\n",
    "\t\t\tis_space = False if letter != ' ' else is_space\n",
    "\t\tj.text = None if is_space else j.text\n",
    "\t\tfor k in j:\n",
    "\t\t\tk.tail = None\n",
    "\t\t\tis_space = True\n",
    "\t\t\tfor letter in k.text:\n",
    "\t\t\t\tis_space = False if letter != ' ' else is_space\n",
    "\t\t\tk.text = None if is_space else k.text\n",
    "\n",
    "\n",
    "# Add article title and metadata to xml tree\n",
    "def add_artice(elem, root, num):\n",
    "\tarticle = ET.SubElement(root, 'article', {'n':str(num)})\n",
    "\ttitle = ET.SubElement(article, 'title')\n",
    "\ttitle.text = file[elem.start_title+1:elem.end_title]\n",
    "\ttitle_meta = ET.SubElement(article, 'title-meta')\n",
    "\ttitle_file = ET.SubElement(title_meta, 'title-file')\n",
    "\ttitle_file.text = elem.filename\n",
    "\ttitle_start = ET.SubElement(title_meta, 'title-start')\n",
    "\ttitle_start.text = str(elem.start_title + 1)\n",
    "\ttitle_end = ET.SubElement(title_meta, 'title-end')\n",
    "\ttitle_end.text = str(elem.end_title)\n",
    "\txml_write(root)\n",
    "\n",
    "\n",
    "# Count number of alphabetic letters in word\n",
    "def count_letters(word):\n",
    "\tnum = 0\n",
    "\tfor letter in word:\n",
    "\t\tnum += 0 if re.match(r\"[A-ZА-Яa-zа-я]\", letter) == None else 1\n",
    "\treturn num\n",
    "\n",
    "# Check if word is written in CAPS\n",
    "def check_caps(word):\n",
    "\tnum = 0\n",
    "\tlen_word = 0\n",
    "\tfor letter in word:\n",
    "\t\t#num += 0 if re.match(r\"[A-ZА-Я0-9]|[!#$%&'*+-.^_`|~:]\", letter) == None else 1\t\t\t\t\t# Too many symbols, math formulas are being detected\n",
    "\t\tlen_word += 1 if re.match(r\"[!#$%&'*+-.^_`|~:]\", letter) == None else 0\n",
    "\t\tnum += 0 if re.match(r\"[A-ZА-Я]\", letter) == None else 1\n",
    "\treturn 0 if len_word == 0 or num / len_word < CAPS_QUOT or word in EXCEPTIONS else num\t\t\t\t# Also exclude common roman numbers\n",
    "\n",
    "# Check for initials like \"I.E.\"\n",
    "def check_initials(word):\n",
    "\tinitials = True\n",
    "\tfor i in range(len(word) - 1):\n",
    "\t\ttype_1 = 0 if re.match(r\"[A-ZА-Яa-zа-я]\", word[i]) == None else 1\n",
    "\t\ttype_2 = 0 if re.match(r\"[A-ZА-Яa-zа-я]\", word[i + 1]) == None else 1\n",
    "\t\tinitials = False if type_1 and type_2 else initials\n",
    "\treturn initials\n",
    "\n",
    "\n",
    "# Find next ot prev word boundary (space / newline)\n",
    "def prev_from(pos, file):\n",
    "\tpos = max(pos, 0)\n",
    "\tprev_space = file.rfind(' ', 0, pos)\n",
    "\tprev_nl = file.rfind('\\n', 0, pos)\n",
    "\tprev_space = -1 if prev_space == -1 else prev_space\n",
    "\tprev_nl = -1 if prev_nl == -1 else prev_nl\n",
    "\treturn max(prev_nl, prev_space)\n",
    "def next_from(pos, file, end_replace = True):\n",
    "\tnext_space = file.find(' ', pos + 1)\n",
    "\tnext_nl = file.find('\\n', pos + 1)\n",
    "\tif end_replace:\n",
    "\t\tnext_space = len(file) if next_space == -1 else next_space\n",
    "\t\tnext_nl = len(file) if next_nl == -1 else next_nl\n",
    "\treturn max(next_nl, next_space) if next_space == -1 or next_nl == -1 else min(next_nl, next_space)\n",
    "\n",
    "\n",
    "# Main loop\n",
    "num = len(root) + 1\n",
    "for filename in filenames:\n",
    "\tprint()\n",
    "\tprint(\"################################ \" + filename + \" ################################\")\n",
    "\twith codecs.open(PAGES_DIR + filename, 'r', 'utf-8') as f:\n",
    "\t\tfile = f.read()\n",
    "\t\n",
    "\tword_bound_l = -1\n",
    "\tword_bound_r = next_from(word_bound_l, file, end_replace=False)\n",
    "\tEOF_reached = False\n",
    "\n",
    "\twhile not EOF_reached:\n",
    "\t\tif word_bound_r == -1:\n",
    "\t\t\tword_bound_r = len(file)\n",
    "\t\t\tEOF_reached = True\n",
    "\n",
    "\n",
    "\t\tif check_caps(file[word_bound_l+1:word_bound_r]) < 2 or check_initials(file[word_bound_l+1:word_bound_r]):\n",
    "\t\t\tword_bound_l = word_bound_r\n",
    "\t\t\tword_bound_r = next_from(word_bound_l, file, end_replace=False)\n",
    "\t\t\n",
    "\t\telse: # Possibly found a title\n",
    "\t\t\t# Left border of a title is already known\n",
    "\t\t\tstart_title = word_bound_l\n",
    "\n",
    "\t\t\t# Define right border of a title\n",
    "\t\t\tdefined_end = False\n",
    "\t\t\tend_title = word_bound_r\n",
    "\t\t\twhile not defined_end:\n",
    "\t\t\t\tword_bound_l = word_bound_r\n",
    "\t\t\t\tword_bound_r = next_from(word_bound_l, file)\n",
    "\n",
    "\t\t\t\tif word_bound_l == len(file):\n",
    "\t\t\t\t\tdefined_end = True\n",
    "\t\t\t\telif not check_caps(file[word_bound_l+1:word_bound_r]) and count_letters(file[word_bound_l+1:word_bound_r]) < 2:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\telif check_caps(file[word_bound_l+1:word_bound_r]):\n",
    "\t\t\t\t\tend_title = word_bound_r\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdefined_end = True\n",
    "\n",
    "\t\t\tnext_title = False\n",
    "\t\t\twhile not next_title:\n",
    "\t\t\t\t# Console output for further user actions\n",
    "\t\t\t\tsegment_start = start_title\n",
    "\t\t\t\tsegment_end = end_title\n",
    "\t\t\t\tfor i in range(LEAD_WORDS):\n",
    "\t\t\t\t\tsegment_start = prev_from(segment_start, file)\n",
    "\t\t\t\tfor i in range(AFT_WORDS):\n",
    "\t\t\t\t\tsegment_end = next_from(segment_end, file)\n",
    "\t\t\t\t\n",
    "\t\t\t\tout_str = file[segment_start+1:segment_end]\n",
    "\n",
    "\t\t\t\t# Format\n",
    "\t\t\t\tfor i in range(len(out_str)):\n",
    "\t\t\t\t\tout_str = out_str[:i] + ('$' if out_str[i] == '\\n' else out_str[i]) + out_str[i+1:]\n",
    "\t\t\t\tout_str = f\"{num})\\n\" + out_str + '\\n' + ' ' * (start_title - segment_start) + '^' * (end_title - start_title - 1)\n",
    "\t\t\t\t# Check for \"section\" in the string. This is referred to alphabetic tip at the bottom of the page\n",
    "\t\t\t\t\"\"\"if 'section' in out_str or 'title' in out_str:\n",
    "\t\t\t\t\tout_str += '     ############################### Title or section found! ###############################'\"\"\" # Not Used\n",
    "\t\t\t\tprint(out_str)\n",
    "\n",
    "\t\t\t\t# User actions\n",
    "\t\t\t\tresponse = input()\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tif response == '':\n",
    "\t\t\t\t\t\t# Add article\n",
    "\t\t\t\t\t\tarticle = Article()\n",
    "\t\t\t\t\t\tarticle.start_title = start_title\n",
    "\t\t\t\t\t\tarticle.end_title = end_title\n",
    "\t\t\t\t\t\tarticle.filename = filename\n",
    "\t\t\t\t\t\tadd_artice(article, root, num)\n",
    "\t\t\t\t\t\tnum += 1\n",
    "\t\t\t\t\t\tnext_title = True\n",
    "\t\t\t\t\t\tprint(f\"Adding article, n=\\\"{num}\\\", title=\\\"{file[start_title+1:end_title]}\\\"\\n\\n\")\n",
    "\t\t\t\t\telif response == 'n' or response == 'т':\n",
    "\t\t\t\t\t\t# Do not add this one\n",
    "\t\t\t\t\t\tnext_title = True\n",
    "\t\t\t\t\t\tprint(\"Not an article, skipping\\n\\n\")\n",
    "\t\t\t\t\telif response[0] == '.':\n",
    "\t\t\t\t\t\tend_title += int(response[1:])\n",
    "\t\t\t\t\t\tprint(\"Changing title right border\\n\\n\")\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t# Change title borders\n",
    "\t\t\t\t\t\tcorrections = response.split(' ')\n",
    "\t\t\t\t\t\tcorrections[0] = int(corrections[0])\n",
    "\t\t\t\t\t\tcorrections[1] = int(corrections[1])\n",
    "\t\t\t\t\t\tif corrections[0] > 0:\n",
    "\t\t\t\t\t\t\tfor i in range(abs(corrections[0])):\n",
    "\t\t\t\t\t\t\t\tstart_title = prev_from(start_title, file)\n",
    "\t\t\t\t\t\tif corrections[0] < 0:\n",
    "\t\t\t\t\t\t\tfor i in range(abs(corrections[0])):\n",
    "\t\t\t\t\t\t\t\tstart_title = next_from(start_title, file)\n",
    "\t\t\t\t\t\tif corrections[1] < 0:\n",
    "\t\t\t\t\t\t\tfor i in range(abs(corrections[1])):\n",
    "\t\t\t\t\t\t\t\tend_title = prev_from(end_title, file)\n",
    "\t\t\t\t\t\tif corrections[1] > 0:\n",
    "\t\t\t\t\t\t\tfor i in range(abs(corrections[1])):\n",
    "\t\t\t\t\t\t\t\tend_title = next_from(end_title, file)\n",
    "\t\t\t\t\t\tprint(\"Changing title borders\\n\\n\")\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tprint(\"########## !!! Failed on input, try again !!! ##########\\n\\n\")\n",
    "\n",
    "\n",
    "# End reached\n",
    "print('###########################################################################################')\n",
    "print('Last requested page processd. Press \"Enter\" to close this window.')\n",
    "response = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исправление ошибок в заголовках\n",
    "\n",
    "Состоит из двух частей: \"составитель\" и \"заменитель\".\n",
    "\n",
    "Сначала формируется xml список всех заголовков с возможными автоматическими исправлениями (в формате было / стало):\n",
    "1. замена латиницы на агалогичную кириллицу;\n",
    "2. удаление обрамляющих знакоав препинания;\n",
    "3. замена всех букв на заглавные (в том числе это избавляет дальнейшей необходимости исправлять имена);\n",
    "4. слияние разорванных на отдельные буквы слов (если рядом оказываются несколько таких слов, то они оказываются слиты вместе).\n",
    "\n",
    "После необходимо его просмотреть и исправить оставшиеся ошибкию\n",
    "\n",
    "Затем запустить \"заменитель\", который заменит все заголовки на исправленныею\n",
    "\n",
    "## Составитель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "\n",
    "############################ VARS ################################\n",
    "WORK_DIR = \"./matphys/\"\n",
    "INPUT_FILE = \"FMEv2.xml\"\n",
    "CORRECTION_FILE = \"FMEcorr.xml\"\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Write xml tree to file\n",
    "def prettify(elem):\n",
    "\t# Pretty-printed XML string for the Element.\n",
    "\trough_string = ET.tostring(elem, 'utf-8')\n",
    "\treparsed = minidom.parseString(rough_string)\n",
    "\treturn reparsed.toprettyxml(indent=\"  \")\n",
    "def xml_write(root):\n",
    "\twith codecs.open(WORK_DIR + CORRECTION_FILE, 'w', 'utf-8') as f:\n",
    "\t\tf.write(prettify(root))\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "# Check for existing xml\n",
    "filenames_raw = next(walk(WORK_DIR), (None, None, []))[2]  # [] if no file\n",
    "if not(INPUT_FILE in filenames_raw):\n",
    "\troot = ET.Element('data')\n",
    "\txml_write(root)\n",
    "\n",
    "\n",
    "# Parse input xml\n",
    "exit_string = ''\n",
    "with codecs.open(WORK_DIR + INPUT_FILE, 'r', 'utf-8') as f:\n",
    "\tfor i in f.readlines():\n",
    "\t\texit_string += i[:-1]\n",
    "root = ET.fromstring(exit_string)\n",
    "\n",
    "\n",
    "# Get all the titles into a dict\n",
    "titles_dict = {}\n",
    "for article in root:\n",
    "\tfor elem in article:\n",
    "\t\tif elem.tag == 'title':\n",
    "\t\t\ttitles_dict[elem.text] = elem.text\n",
    "\n",
    "\n",
    "# Correct latin letters\n",
    "letter_corr = {'A':'А', 'a':'а', 'B':'В', 'b':'Ь', 'E':'Е', 'e':'е', 'H':'Н', 'K':'К', 'M':'М', 'O':'О', 'P':'Р', 'p':'р', 'T':'Т', 'X':'Х', 'x':'x', 'y':'у', '6':'б'}\n",
    "# Rarely seen\n",
    "letter_corr['U'] = 'И'\n",
    "letter_corr['r'] = 'г'\n",
    "letter_corr['n'] = 'п'\n",
    "for title in titles_dict.keys():\n",
    "\ttitle_new = titles_dict[title]\n",
    "\tfor i in range(len(title_new)):\n",
    "\t\tif title_new[i] in letter_corr:\n",
    "\t\t\ttitle_new = title_new[:i] + letter_corr[title_new[i]] + title_new[i+1:]\n",
    "\ttitles_dict[title] = title_new\n",
    "\n",
    "# Remove bounding symbols\n",
    "for title in titles_dict.keys():\n",
    "\ttitle_new = titles_dict[title]\n",
    "\twhile re.match(r\"[!#%&'*+-.^_`|~:]\", title_new[0]) != None:\n",
    "\t\ttitle_new = title_new[1:]\n",
    "\twhile re.match(r\"[!#%&'*+-.^_`|~:]\", title_new[-1]) != None:\n",
    "\t\ttitle_new = title_new[:-1]\n",
    "\ttitles_dict[title] = title_new\n",
    "\n",
    "# CAPS\n",
    "for title in titles_dict.keys():\n",
    "\ttitles_dict[title] = titles_dict[title].upper()\n",
    "\n",
    "# Merge single-lettered words\n",
    "for title in titles_dict.keys():\n",
    "\ttitle_new = titles_dict[title]\n",
    "\ttitle_new = ' ' + title_new + ' '\n",
    "\tfor i in range(len(title_new) - 4):\n",
    "\t\tif (title_new[i] == ' ' or title_new[i] == '№') and title_new[i + 2] == ' ' and title_new[i + 4] == ' ':\n",
    "\t\t\ttitle_new = title_new[:i+2] + '№' + title_new[i+3:]\n",
    "\ti = 0\n",
    "\twhile i < len(title_new):\n",
    "\t\tif title_new[i] == '№':\n",
    "\t\t\ttitle_new = title_new[:i] + title_new[i+1:]\n",
    "\t\t\ti = 0\n",
    "\t\telse:\n",
    "\t\t\ti += 1\n",
    "\ttitle_new = title_new[1:-1]\n",
    "\ttitles_dict[title] = title_new\n",
    "\n",
    "\n",
    "# Write corrections xml\n",
    "root = ET.Element('data')\n",
    "for i in titles_dict.items():\n",
    "\tpair = ET.SubElement(root, 'pair')\n",
    "\ttitle_old = ET.SubElement(pair, 'title_old')\n",
    "\ttitle_old.text = i[0]\n",
    "\ttitle_new = ET.SubElement(pair, 'title_new')\n",
    "\ttitle_new.text = i[1]\n",
    "xml_write(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заменитель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "\n",
    "############################ VARS ################################\n",
    "WORK_DIR = \"./matphys/\"\n",
    "INPUT_FILE = \"FMEv2.xml\"\n",
    "CORRECTION_FILE = \"FMEcorr.xml\"\n",
    "EXIT_FILE = \"FMEtitles.xml\"\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Write xml tree to file\n",
    "def prettify(elem):\n",
    "\t# Pretty-printed XML string for the Element.\n",
    "\trough_string = ET.tostring(elem, 'utf-8')\n",
    "\treparsed = minidom.parseString(rough_string)\n",
    "\treturn reparsed.toprettyxml(indent=\"  \")\n",
    "def xml_write(root):\n",
    "\twith codecs.open(WORK_DIR + EXIT_FILE, 'w', 'utf-8') as f:\n",
    "\t\tf.write(prettify(root))\n",
    "\n",
    "\n",
    "# Parse input xml\n",
    "exit_string = ''\n",
    "with codecs.open(WORK_DIR + CORRECTION_FILE, 'r', 'utf-8') as f:\n",
    "\tfor i in f.readlines():\n",
    "\t\texit_string += i[:-1]\n",
    "root = ET.fromstring(exit_string)\n",
    "\n",
    "\n",
    "# Get all the corrections into a dict\n",
    "titles_dict = {}\n",
    "for pair in root:\n",
    "\tfor elem in pair:\n",
    "\t\tif elem.tag == 'title_old':\n",
    "\t\t\ttitle_old = elem.text\n",
    "\t\tif elem.tag == 'title_new':\n",
    "\t\t\ttitle_new = elem.text\n",
    "\ttitles_dict[title_old] = title_new\n",
    "\n",
    "\n",
    "# Parse existing exit xml (string parsing is needed to avoid extra newlines appearing)\n",
    "exit_string = ''\n",
    "with codecs.open(WORK_DIR + INPUT_FILE, 'r', 'utf-8') as f:\n",
    "\tfor i in f.readlines():\n",
    "\t\texit_string += i[:-1]\n",
    "root = ET.fromstring(exit_string)\n",
    "# Remove empty tails and texts\n",
    "root.tail = None\n",
    "root.text = None\n",
    "for i in root:\n",
    "\ti.tail = None\n",
    "\ti.text = None\n",
    "\tfor j in i:\n",
    "\t\tj.tail = None\n",
    "\t\tis_space = True\n",
    "\t\tfor letter in j.text:\n",
    "\t\t\tis_space = False if letter != ' ' else is_space\n",
    "\t\tj.text = None if is_space else j.text\n",
    "\t\tfor k in j:\n",
    "\t\t\tk.tail = None\n",
    "\t\t\tis_space = True\n",
    "\t\t\tfor letter in k.text:\n",
    "\t\t\t\tis_space = False if letter != ' ' else is_space\n",
    "\t\t\tk.text = None if is_space else k.text\n",
    "\n",
    "\n",
    "# Replace titles\n",
    "for article in root:\n",
    "\tfor elem in article:\n",
    "\t\tif elem.tag == 'title':\n",
    "\t\t\telem.text = titles_dict[elem.text]\n",
    "xml_write(root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
